{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "4075517e-3967-403c-bff6-005582374c48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras  # noqa: F401\n",
    "from keras import optimizers as tfoptim\n",
    "from keras import losses as tfloss\n",
    "\n",
    "import torch\n",
    "import torch.optim as torchoptim\n",
    "import torch.nn.modules.loss as torchloss\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "\n",
    "import flatiron.core.tools as fict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "id": "db3144b2-94d8-4baf-9d91-1711572a1690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_classes(module):\n",
    "    members = inspect.getmembers(module)\n",
    "    members = list(filter(lambda x: inspect.isclass(x[1]), members))\n",
    "    members = list(filter(lambda x: not x[0].startswith('_'), members))\n",
    "    classes = dict(members)\n",
    "    return classes\n",
    "\n",
    "def create_signature(arg, annotation, default):\n",
    "    if annotation == 'UNTYPED':\n",
    "        annotation = 'Any'\n",
    "    if default == 'REQUIRED':\n",
    "        default = ''\n",
    "    else:\n",
    "        default = f' = {default}'\n",
    "    return f'{arg}: {annotation}{default}'\n",
    "\n",
    "def get_init_signature_data(class_, remove=['self']):\n",
    "    sig = inspect.getfullargspec(class_)\n",
    "    args = sig.args\n",
    "    for item in remove:\n",
    "        args.remove(item)\n",
    "\n",
    "    if sig.defaults is not None:\n",
    "        d = len(args) - len(sig.defaults)\n",
    "        req = args[:d]\n",
    "        opt = args[d:]\n",
    "        args = {k: 'REQUIRED' for k in req}\n",
    "        opt = dict(zip(opt, sig.defaults))\n",
    "        args.update(opt)\n",
    "    else:\n",
    "        args = {k: 'REQUIRED' for k in args}\n",
    "    \n",
    "    if isinstance(sig.kwonlydefaults, dict):\n",
    "        args.update(sig.kwonlydefaults)\n",
    "    \n",
    "    anno = sig.annotations\n",
    "    for key, val in args.items():\n",
    "        if key in anno:\n",
    "            args[key] = (val, anno[key].__name__)\n",
    "        else:\n",
    "            args[key] = (val, 'UNTYPED')\n",
    "            \n",
    "    data = []\n",
    "    for arg, (default, type_) in args.items():\n",
    "        data.append(dict(\n",
    "            arg=arg,\n",
    "            default=default,\n",
    "            type_=type_,\n",
    "            signature=create_signature(arg, type_, default),\n",
    "        ))\n",
    "    return data\n",
    "\n",
    "def get_module_class_data(module):\n",
    "    classes = get_classes(module)\n",
    "    data = []\n",
    "    for name, item in classes.items():\n",
    "        try:\n",
    "            datum = get_init_signature_data(item)\n",
    "        except:\n",
    "            continue\n",
    "        for row in datum:\n",
    "            row['class_'] = name\n",
    "        data.extend(datum)\n",
    "        \n",
    "    cols = ['class_', 'arg', 'type_', 'default', 'signature']\n",
    "    data = pd.DataFrame(data, columns=cols)\n",
    "    data['library'] = module.__name__.split('.')[0]\n",
    "    data['module'] = module.__name__\n",
    "    cols.insert(0, 'library')\n",
    "    cols.insert(1, 'module')\n",
    "    data = data[cols]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_optimizer_data():\n",
    "    tf_optim_data = get_module_class_data(tfoptim)\n",
    "    torch_optim_data = get_module_class_data(torchoptim)\n",
    "    data = pd.concat([tf_optim_data, torch_optim_data], axis=0)\n",
    "    \n",
    "    mask = data.library == 'keras'\n",
    "    data.loc[mask, 'library'] = 'tf'\n",
    "    \n",
    "    data['field'] = data['class_']\n",
    "    mask = data.field == 'Nadam'\n",
    "    data.loc[mask, 'field'] = 'NAdam'\n",
    "    \n",
    "    mask = data.class_.apply(lambda x: x not in ['Optimizer', 'LossScaleOptimizer'])\n",
    "    data = data[mask]\n",
    "    \n",
    "    mask = data.arg != 'params'\n",
    "    data = data[mask]\n",
    "\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_loss_data():\n",
    "    tf_loss_data = get_module_class_data(tfloss)\n",
    "    torch_loss_data = get_module_class_data(torchloss)\n",
    "    data = pd.concat([tf_loss_data, torch_loss_data], axis=0)\n",
    "    \n",
    "    mask = data.library == 'keras'\n",
    "    data.loc[mask, 'library'] = 'tf'\n",
    "    \n",
    "#     data['field'] = data['class_']\n",
    "#     mask = data.field == 'Nadam'\n",
    "#     data.loc[mask, 'field'] = 'NAdam'\n",
    "    \n",
    "    mask = data.class_.apply(lambda x: x not in ['deprecated'])\n",
    "    data = data[mask]\n",
    "    \n",
    "#     mask = data.arg != 'params'\n",
    "#     data = data[mask]\n",
    "\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_class_definitions(data, base_class='BaseConfig'):\n",
    "    data = data.copy()\n",
    "    data['config_name'] = data \\\n",
    "        .apply(lambda x: f'class {x.library.capitalize()}{x.class_}Config({base_class}):', axis=1) \\\n",
    "        .apply(lambda x: re.sub(' Tf', ' TF', x))\n",
    "    class_def = data.groupby('config_name', as_index=False).signature.agg(lambda x: '    ' + '\\n    '.join(sorted(x)))\n",
    "    class_def = class_def.apply(lambda x: f'{x.config_name}\\n{x.signature}', axis=1)\n",
    "    return class_def.tolist()\n",
    "\n",
    "def get_comparison_data(data, mask=None):\n",
    "    data = data.copy()\n",
    "    if mask is not None:\n",
    "        mask = data.library == mask\n",
    "        data = data[mask]\n",
    "    data = data.groupby('arg', as_index=False)[['library', 'class_']].agg(lambda x: x.unique())\n",
    "    data['len_library'] = data.library.apply(len)\n",
    "    data['len_class'] = data.class_.apply(len)\n",
    "    data.sort_values(['len_class', 'len_library'], ascending=False, inplace=True)\n",
    "    return data\n",
    "\n",
    "def get_comparison_checkboxes(data, mask=None):\n",
    "    data = get_comparison_data(data, mask=mask)\n",
    "    output = data.class_.apply(lambda x: {k: k for k in x}).tolist()\n",
    "    index = data.arg.tolist()\n",
    "    output = pd.DataFrame(output, index=index).map(lambda x: '' if pd.isnull(x) else 'x')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fc4d25f8-76e7-4713-89b3-6d21c667e0c1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_tf_optimizer_config_definitions():\n",
    "    # TF\n",
    "    d = get_optimizer_data()\n",
    "    mask = d.library == 'tf'\n",
    "    d = d[mask]\n",
    "\n",
    "    # TFBaseConfig\n",
    "    tf_base_args = [\n",
    "        'clipnorm',\n",
    "        'clipvalue',\n",
    "        'ema_momentum',\n",
    "        'ema_overwrite_frequency',\n",
    "        'global_clipnorm',\n",
    "        'gradient_accumulation_steps',\n",
    "        'learning_rate',\n",
    "        'loss_scale_factor',\n",
    "        'name',\n",
    "        'use_ema',\n",
    "        'weight_decay',\n",
    "    ]\n",
    "    mask = d.arg.apply(lambda x: x in tf_base_args)\n",
    "    d0 = d[mask]\n",
    "    tf_base = get_class_definitions(d0)[0]\n",
    "    tf_base = re.sub('TFAdadeltaConfig', 'TFBaseConfig', tf_base)\n",
    "    print(tf_base, '\\n\\n')\n",
    "\n",
    "    # TFEpsilonBaseConfig\n",
    "    tf_eps_args = ['epsilon']\n",
    "    mask = d.arg.apply(lambda x: x in tf_eps_args)\n",
    "    d1 = d[mask]\n",
    "    tf_eps = get_class_definitions(d1, 'TFBaseConfig')[0]\n",
    "    tf_eps = re.sub('class TF[a-zA-Z]*Config', 'class TFEpsilonBaseConfig', tf_eps)\n",
    "    print(tf_eps, '\\n\\n')\n",
    "    \n",
    "    # TFEpsilonBaseConfig\n",
    "    tf_eps_args = ['epsilon']\n",
    "    mask = d.arg.apply(lambda x: x in tf_eps_args)\n",
    "    d1 = d[mask]\n",
    "    tf_eps = get_class_definitions(d1, 'TFBaseConfig')[0]\n",
    "    tf_eps = re.sub('class TF[a-zA-Z]*Config', 'class TFEpsilonBaseConfig', tf_eps)\n",
    "    print(tf_eps, '\\n\\n')\n",
    "\n",
    "    # TFBaseConfig subclasses\n",
    "    eps_classes = d1.class_.unique().tolist()\n",
    "    mask = d.class_.apply(lambda x: x in eps_classes)\n",
    "    d2 = d[~mask]\n",
    "    mask = d2.arg.apply(lambda x: x in tf_base_args)\n",
    "    d2 = d2[~mask]\n",
    "    tf_subclass = get_class_definitions(d2, 'TFBaseConfig')\n",
    "    for item in tf_subclass:\n",
    "        print(item, '\\n\\n')\n",
    "\n",
    "    # TFEpsilonBaseConfig subclasses\n",
    "    eps_classes = d1.class_.unique().tolist()\n",
    "    mask = d.class_.apply(lambda x: x in eps_classes)\n",
    "    d2 = d[mask]\n",
    "    mask = d2.arg.apply(lambda x: x in tf_base_args or x in tf_eps_args)\n",
    "    d2 = d2[~mask]\n",
    "    tf_eps_subclass = get_class_definitions(d2, 'TFEpsilonBaseConfig')\n",
    "    for item in tf_eps_subclass:\n",
    "        print(item, '\\n\\n')\n",
    "\n",
    "\n",
    "def print_torch_optimizer_config_definitions():\n",
    "    def get_base_class(data, arg, class_, base_class):\n",
    "        mask = data.arg.apply(lambda x: x == arg)\n",
    "        temp = data[mask]\n",
    "        result = get_class_definitions(temp, base_class)[0]\n",
    "        result = re.sub('class Torch[a-zA-Z]*Config', f'class {class_}', result)\n",
    "        return result\n",
    "    \n",
    "    def get_torch_class_definition(class_, inherit, signature):\n",
    "        inherit = ', '.join(sorted(filter(lambda x: x != '', inherit)))\n",
    "        output = f'class Torch{class_}Config(TorchBaseConfig, {inherit}):\\n    '\n",
    "        output = re.sub(', \\)', ')', output)\n",
    "        regex = '(params|lr|maximize|foreach|differentiable|eps|capturable|weight_decay):'\n",
    "        signature = list(filter(lambda x: not re.search(regex, x), signature))\n",
    "        output +=  '\\n    '.join(sorted(signature))\n",
    "        return output\n",
    "\n",
    "    # Torch\n",
    "    data = get_optimizer_data()\n",
    "    mask = data.library == 'torch'\n",
    "    data = data[mask]\n",
    "\n",
    "    # TFBaseConfig\n",
    "    mask = data.arg.apply(lambda x: x == 'lr')\n",
    "    d0 = data[mask]\n",
    "    torch_base = get_class_definitions(d0)[0]\n",
    "    torch_base = re.sub('TorchASGDConfig', 'TorchBaseConfig', torch_base)\n",
    "    print(torch_base, '\\n\\n')    \n",
    "    \n",
    "    # aux base configs\n",
    "    lut = [\n",
    "        ('maximize', 'TMax'),\n",
    "        ('foreach', 'TFor'),\n",
    "        ('differentiable', 'TDiff'),\n",
    "        ('eps', 'TEps'),\n",
    "        ('capturable', 'TCap'),\n",
    "        ('weight_decay', 'TDecay'),\n",
    "    ]\n",
    "    data['inherit'] = ''\n",
    "    for arg, cls_ in lut:\n",
    "        print(get_base_class(data, arg, cls_, 'TorchBaseConfig'), '\\n\\n')\n",
    "        mask = data.arg == arg\n",
    "        data.loc[mask, 'inherit'] = cls_\n",
    "    \n",
    "    # classes\n",
    "    class_def = data \\\n",
    "        .sort_values('class_') \\\n",
    "        .groupby('class_', as_index=False)[['inherit', 'signature']] \\\n",
    "        .agg(lambda x: x) \\\n",
    "        .apply(lambda x: get_torch_class_definition(x.class_, x.inherit, x.signature), axis=1) \\\n",
    "        .tolist()  \n",
    "    for item in class_def:\n",
    "        print(item, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "id": "6f7b1755-b094-4b47-8850-658ccfc756e1",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class TFBaseConfig(BaseConfig):\n",
      "    name: Any = binary_crossentropy \n",
      "\n",
      "\n",
      "class TFAxis(TFBaseConfig):\n",
      "    axis: Any = -1 \n",
      "\n",
      "\n",
      "class TFLogits(TFBaseConfig):\n",
      "    from_logits: Any = False \n",
      "\n",
      "\n",
      "class TFBinaryCrossentropyConfig(TFBaseConfig, TFAxis, TFLogits):\n",
      "    dtype: Any = None\n",
      "    label_smoothing: Any = 0.0\n",
      "    reduction: Any = sum_over_batch_size \n",
      "\n",
      "\n",
      "class TFBinaryFocalCrossentropyConfig(TFBaseConfig, TFAxis, TFLogits):\n",
      "    alpha: Any = 0.25\n",
      "    apply_class_balancing: Any = False\n",
      "    dtype: Any = None\n",
      "    gamma: Any = 2.0\n",
      "    label_smoothing: Any = 0.0\n",
      "    reduction: Any = sum_over_batch_size \n",
      "\n",
      "\n",
      "class TFCTCConfig(TFBaseConfig):\n",
      "    dtype: Any = None\n",
      "    reduction: Any = sum_over_batch_size \n",
      "\n",
      "\n",
      "class TFCategoricalCrossentropyConfig(TFBaseConfig, TFAxis, TFLogits):\n",
      "    dtype: Any = None\n",
      "    label_smoothing: Any = 0.0\n",
      "    reduction: Any = sum_over_batch_size \n",
      "\n",
      "\n",
      "class TFCategoricalFocalCrossentropyConfig(TFBaseConfig, TFAxis, TFLogits):\n",
      "    alpha: Any = 0.25\n",
      "    dtype: Any = None\n",
      "    gamma: Any = 2.0\n",
      "    label_smoothing: Any = 0.0\n",
      "    reduction: Any = sum_over_batch_size \n",
      "\n",
      "\n",
      "class TFCategoricalHingeConfig(TFBaseConfig):\n",
      "    dtype: Any = None\n",
      "    reduction: Any = sum_over_batch_size \n",
      "\n",
      "\n",
      "class TFCircleConfig(TFBaseConfig):\n",
      "    dtype: Any = None\n",
      "    gamma: Any = 80.0\n",
      "    margin: Any = 0.4\n",
      "    reduction: Any = sum_over_batch_size\n",
      "    remove_diagonal: Any = True \n",
      "\n",
      "\n",
      "class TFCosineSimilarityConfig(TFBaseConfig, TFAxis):\n",
      "    dtype: Any = None\n",
      "    reduction: Any = sum_over_batch_size \n",
      "\n",
      "\n",
      "class TFDiceConfig(TFBaseConfig, TFAxis):\n",
      "    dtype: Any = None\n",
      "    reduction: Any = sum_over_batch_size \n",
      "\n",
      "\n",
      "class TFHingeConfig(TFBaseConfig):\n",
      "    dtype: Any = None\n",
      "    reduction: Any = sum_over_batch_size \n",
      "\n",
      "\n",
      "class TFHuberConfig(TFBaseConfig):\n",
      "    delta: Any = 1.0\n",
      "    dtype: Any = None\n",
      "    reduction: Any = sum_over_batch_size \n",
      "\n",
      "\n",
      "class TFKLDivergenceConfig(TFBaseConfig):\n",
      "    dtype: Any = None\n",
      "    reduction: Any = sum_over_batch_size \n",
      "\n",
      "\n",
      "class TFLogCoshConfig(TFBaseConfig):\n",
      "    dtype: Any = None\n",
      "    reduction: Any = sum_over_batch_size \n",
      "\n",
      "\n",
      "class TFLossConfig(TFBaseConfig):\n",
      "    dtype: Any = None\n",
      "    reduction: Any = sum_over_batch_size \n",
      "\n",
      "\n",
      "class TFMeanAbsoluteErrorConfig(TFBaseConfig):\n",
      "    dtype: Any = None\n",
      "    reduction: Any = sum_over_batch_size \n",
      "\n",
      "\n",
      "class TFMeanAbsolutePercentageErrorConfig(TFBaseConfig):\n",
      "    dtype: Any = None\n",
      "    reduction: Any = sum_over_batch_size \n",
      "\n",
      "\n",
      "class TFMeanSquaredErrorConfig(TFBaseConfig):\n",
      "    dtype: Any = None\n",
      "    reduction: Any = sum_over_batch_size \n",
      "\n",
      "\n",
      "class TFMeanSquaredLogarithmicErrorConfig(TFBaseConfig):\n",
      "    dtype: Any = None\n",
      "    reduction: Any = sum_over_batch_size \n",
      "\n",
      "\n",
      "class TFPoissonConfig(TFBaseConfig):\n",
      "    dtype: Any = None\n",
      "    reduction: Any = sum_over_batch_size \n",
      "\n",
      "\n",
      "class TFSparseCategoricalCrossentropyConfig(TFBaseConfig, TFLogits):\n",
      "    dtype: Any = None\n",
      "    ignore_class: Any = None\n",
      "    reduction: Any = sum_over_batch_size \n",
      "\n",
      "\n",
      "class TFSquaredHingeConfig(TFBaseConfig):\n",
      "    dtype: Any = None\n",
      "    reduction: Any = sum_over_batch_size \n",
      "\n",
      "\n",
      "class TFTverskyConfig(TFBaseConfig, TFAxis):\n",
      "    alpha: Any = 0.5\n",
      "    beta: Any = 0.5\n",
      "    dtype: Any = None\n",
      "    reduction: Any = sum_over_batch_size \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# def print_tf_optimizer_config_definitions():\n",
    "#     def get_base_class(data, arg, class_, base_class):\n",
    "#         mask = data.arg.apply(lambda x: x == arg)\n",
    "#         temp = data[mask]\n",
    "#         result = get_class_definitions(temp, base_class)[0]\n",
    "#         result = re.sub('class TF[a-zA-Z]*Config', f'class {class_}', result)\n",
    "#         return result\n",
    "    \n",
    "#     def get_tf_class_definition(class_, inherit, signature):\n",
    "#         inherit = ', '.join(sorted(filter(lambda x: x != '', inherit)))\n",
    "#         output = f'class TF{class_}Config(TFBaseConfig, {inherit}):\\n    '\n",
    "#         output = re.sub(', \\)', ')', output)\n",
    "#         regex = '(epsilon|beta_1|beta_2):'\n",
    "#         signature = list(filter(lambda x: not re.search(regex, x), signature))\n",
    "#         output +=  '\\n    '.join(sorted(signature))\n",
    "#         return output\n",
    "\n",
    "#     # TF\n",
    "#     data = get_optimizer_data()\n",
    "#     mask = data.library == 'tf'\n",
    "#     data = data[mask]\n",
    "\n",
    "#     # TFBaseConfig\n",
    "#     args = [\n",
    "#         'clipnorm',\n",
    "#         'clipvalue',\n",
    "#         'ema_momentum',\n",
    "#         'ema_overwrite_frequency',\n",
    "#         'global_clipnorm',\n",
    "#         'gradient_accumulation_steps',\n",
    "#         'learning_rate',\n",
    "#         'loss_scale_factor',\n",
    "#         'name',\n",
    "#         'use_ema',\n",
    "#         'weight_decay',\n",
    "#     ]\n",
    "#     mask = data.arg.apply(lambda x: x in args)\n",
    "#     d0 = data[mask]\n",
    "#     tf_base = get_class_definitions(d0)[0]\n",
    "#     tf_base = re.sub('TF[a-zA-Z]*Config', 'TFBaseConfig', tf_base)\n",
    "#     print(tf_base, '\\n\\n')    \n",
    "    \n",
    "#     # aux base configs\n",
    "#     lut = [\n",
    "#         ('epsilon', 'TFEps'),\n",
    "#         ('beta_1', 'TFBeta'),\n",
    "#     ]\n",
    "#     data['inherit'] = ''\n",
    "#     for arg, cls_ in lut:\n",
    "#         print(get_base_class(data, arg, cls_, 'TFBaseConfig'), '\\n\\n')\n",
    "#         mask = data.arg == arg\n",
    "#         data.loc[mask, 'inherit'] = cls_\n",
    "    \n",
    "#     # classes\n",
    "#     mask = data.arg.apply(lambda x: x not in args)\n",
    "#     d1 = data[mask]\n",
    "#     class_def = d1 \\\n",
    "#         .groupby('class_', as_index=False)[['inherit', 'signature']] \\\n",
    "#         .agg(lambda x: x) \\\n",
    "#         .apply(lambda x: get_tf_class_definition(x.class_, x.inherit, x.signature), axis=1) \\\n",
    "#         .tolist()  \n",
    "#     for item in class_def:\n",
    "#         print(item, '\\n\\n')\n",
    "        \n",
    "# print_tf_optimizer_config_definitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f0d4c322-6b9b-4f8f-b7d0-40809ee41913",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class TFBaseConfig(BaseConfig):\n",
      "    clipnorm: Any = None\n",
      "    clipvalue: Any = None\n",
      "    ema_momentum: Any = 0.99\n",
      "    ema_overwrite_frequency: Any = None\n",
      "    global_clipnorm: Any = None\n",
      "    gradient_accumulation_steps: Any = None\n",
      "    learning_rate: Any = 0.001\n",
      "    loss_scale_factor: Any = None\n",
      "    name: Any = adadelta\n",
      "    use_ema: Any = False\n",
      "    weight_decay: Any = None \n",
      "\n",
      "\n",
      "class TFEpsilonBaseConfig(TFBaseConfig):\n",
      "    epsilon: Any = 1e-07 \n",
      "\n",
      "\n",
      "class TFEpsilonBaseConfig(TFBaseConfig):\n",
      "    epsilon: Any = 1e-07 \n",
      "\n",
      "\n",
      "class TFAdafactorConfig(TFBaseConfig):\n",
      "    beta_2_decay: Any = -0.8\n",
      "    clip_threshold: Any = 1.0\n",
      "    epsilon_1: Any = 1e-30\n",
      "    epsilon_2: Any = 0.001\n",
      "    relative_step: Any = True \n",
      "\n",
      "\n",
      "class TFFtrlConfig(TFBaseConfig):\n",
      "    beta: Any = 0.0\n",
      "    initial_accumulator_value: Any = 0.1\n",
      "    l1_regularization_strength: Any = 0.0\n",
      "    l2_regularization_strength: Any = 0.0\n",
      "    l2_shrinkage_regularization_strength: Any = 0.0\n",
      "    learning_rate_power: Any = -0.5 \n",
      "\n",
      "\n",
      "class TFLionConfig(TFBaseConfig):\n",
      "    beta_1: Any = 0.9\n",
      "    beta_2: Any = 0.99 \n",
      "\n",
      "\n",
      "class TFSGDConfig(TFBaseConfig):\n",
      "    momentum: Any = 0.0\n",
      "    nesterov: Any = False \n",
      "\n",
      "\n",
      "class TFAdadeltaConfig(TFEpsilonBaseConfig):\n",
      "    rho: Any = 0.95 \n",
      "\n",
      "\n",
      "class TFAdagradConfig(TFEpsilonBaseConfig):\n",
      "    initial_accumulator_value: Any = 0.1 \n",
      "\n",
      "\n",
      "class TFAdamConfig(TFEpsilonBaseConfig):\n",
      "    amsgrad: Any = False\n",
      "    beta_1: Any = 0.9\n",
      "    beta_2: Any = 0.999 \n",
      "\n",
      "\n",
      "class TFAdamWConfig(TFEpsilonBaseConfig):\n",
      "    amsgrad: Any = False\n",
      "    beta_1: Any = 0.9\n",
      "    beta_2: Any = 0.999 \n",
      "\n",
      "\n",
      "class TFAdamaxConfig(TFEpsilonBaseConfig):\n",
      "    beta_1: Any = 0.9\n",
      "    beta_2: Any = 0.999 \n",
      "\n",
      "\n",
      "class TFLambConfig(TFEpsilonBaseConfig):\n",
      "    beta_1: Any = 0.9\n",
      "    beta_2: Any = 0.999 \n",
      "\n",
      "\n",
      "class TFNadamConfig(TFEpsilonBaseConfig):\n",
      "    beta_1: Any = 0.9\n",
      "    beta_2: Any = 0.999 \n",
      "\n",
      "\n",
      "class TFRMSpropConfig(TFEpsilonBaseConfig):\n",
      "    centered: Any = False\n",
      "    momentum: Any = 0.0\n",
      "    rho: Any = 0.9 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tf_optimizer_config_definitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "id": "a60c6488-24c9-4a6f-bb95-c9f222498b8d",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class TorchBaseConfig(BaseConfig):\n",
      "    lr: Union = 0.01 \n",
      "\n",
      "\n",
      "class TMax(TorchBaseConfig):\n",
      "    maximize: bool = False \n",
      "\n",
      "\n",
      "class TFor(TorchBaseConfig):\n",
      "    foreach: Optional = None \n",
      "\n",
      "\n",
      "class TDiff(TorchBaseConfig):\n",
      "    differentiable: bool = False \n",
      "\n",
      "\n",
      "class TEps(TorchBaseConfig):\n",
      "    eps: float = 1e-06 \n",
      "\n",
      "\n",
      "class TCap(TorchBaseConfig):\n",
      "    capturable: bool = False \n",
      "\n",
      "\n",
      "class TDecay(TorchBaseConfig):\n",
      "    weight_decay: float = 0 \n",
      "\n",
      "\n",
      "class TorchASGDConfig(TorchBaseConfig, TCap, TDecay, TDiff, TFor, TMax):\n",
      "    alpha: float = 0.75\n",
      "    lambd: float = 0.0001\n",
      "    t0: float = 1000000.0 \n",
      "\n",
      "\n",
      "class TorchAdadeltaConfig(TorchBaseConfig, TCap, TDecay, TDiff, TEps, TFor, TMax):\n",
      "    rho: float = 0.9 \n",
      "\n",
      "\n",
      "class TorchAdafactorConfig(TorchBaseConfig, TDecay, TEps, TFor, TMax):\n",
      "    beta2_decay: float = -0.8\n",
      "    d: float = 1.0 \n",
      "\n",
      "\n",
      "class TorchAdagradConfig(TorchBaseConfig, TDecay, TDiff, TEps, TFor, TMax):\n",
      "    fused: Optional = None\n",
      "    initial_accumulator_value: float = 0\n",
      "    lr_decay: float = 0 \n",
      "\n",
      "\n",
      "class TorchAdamConfig(TorchBaseConfig, TCap, TDecay, TDiff, TEps, TFor, TMax):\n",
      "    amsgrad: bool = False\n",
      "    betas: Tuple = (0.9, 0.999)\n",
      "    fused: Optional = None \n",
      "\n",
      "\n",
      "class TorchAdamWConfig(TorchBaseConfig, TCap, TDecay, TDiff, TEps, TFor, TMax):\n",
      "    amsgrad: bool = False\n",
      "    betas: Tuple = (0.9, 0.999)\n",
      "    fused: Optional = None \n",
      "\n",
      "\n",
      "class TorchAdamaxConfig(TorchBaseConfig, TCap, TDecay, TDiff, TEps, TFor, TMax):\n",
      "    betas: Tuple = (0.9, 0.999) \n",
      "\n",
      "\n",
      "class TorchLBFGSConfig(TorchBaseConfig):\n",
      "    history_size: int = 100\n",
      "    line_search_fn: Optional = None\n",
      "    max_eval: Optional = None\n",
      "    max_iter: int = 20\n",
      "    tolerance_change: float = 1e-09\n",
      "    tolerance_grad: float = 1e-07 \n",
      "\n",
      "\n",
      "class TorchNAdamConfig(TorchBaseConfig, TCap, TDecay, TDiff, TEps, TFor, TMax):\n",
      "    betas: Tuple = (0.9, 0.999)\n",
      "    momentum_decay: float = 0.004 \n",
      "\n",
      "\n",
      "class TorchRAdamConfig(TorchBaseConfig, TCap, TDecay, TDiff, TEps, TFor, TMax):\n",
      "    betas: Tuple = (0.9, 0.999) \n",
      "\n",
      "\n",
      "class TorchRMSpropConfig(TorchBaseConfig, TCap, TDecay, TDiff, TEps, TFor, TMax):\n",
      "    alpha: float = 0.99\n",
      "    centered: bool = False\n",
      "    momentum: float = 0 \n",
      "\n",
      "\n",
      "class TorchRpropConfig(TorchBaseConfig, TCap, TDiff, TFor, TMax):\n",
      "    etas: Tuple = (0.5, 1.2)\n",
      "    step_sizes: Tuple = (1e-06, 50) \n",
      "\n",
      "\n",
      "class TorchSGDConfig(TorchBaseConfig, TDecay, TDiff, TFor, TMax):\n",
      "    dampening: float = 0\n",
      "    fused: Optional = None\n",
      "    momentum: float = 0\n",
      "    nesterov: bool = False \n",
      "\n",
      "\n",
      "class TorchSparseAdamConfig(TorchBaseConfig, TEps, TMax):\n",
      "    betas: Tuple = (0.9, 0.999) \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_torch_optimizer_config_definitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "dd65c25f-6c16-423b-9fdf-467e4a883cbe",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class TFLossBaseConfig(BaseConfig):\n",
      "    dtype: Any = None\n",
      "    name: Any = binary_crossentropy\n",
      "    reduction: Any = sum_over_batch_size \n",
      "\n",
      "\n",
      "class TFAxis(TFLossBaseConfig):\n",
      "    axis: Any = -1 \n",
      "\n",
      "\n",
      "class TFLogits(TFLossBaseConfig):\n",
      "    from_logits: Any = False \n",
      "\n",
      "\n",
      "class TFLossBinaryCrossentropyConfig(TFLossBaseConfig, TFAxis, TFLogits):\n",
      "    label_smoothing: Any = 0.0 \n",
      "\n",
      "\n",
      "class TFLossBinaryFocalCrossentropyConfig(TFLossBaseConfig, TFAxis, TFLogits):\n",
      "    alpha: Any = 0.25\n",
      "    apply_class_balancing: Any = False\n",
      "    gamma: Any = 2.0\n",
      "    label_smoothing: Any = 0.0 \n",
      "\n",
      "\n",
      "class TFLossCategoricalCrossentropyConfig(TFLossBaseConfig, TFAxis, TFLogits):\n",
      "    label_smoothing: Any = 0.0 \n",
      "\n",
      "\n",
      "class TFLossCategoricalFocalCrossentropyConfig(TFLossBaseConfig, TFAxis, TFLogits):\n",
      "    alpha: Any = 0.25\n",
      "    gamma: Any = 2.0\n",
      "    label_smoothing: Any = 0.0 \n",
      "\n",
      "\n",
      "class TFLossCircleConfig(TFLossBaseConfig):\n",
      "    gamma: Any = 80.0\n",
      "    margin: Any = 0.4\n",
      "    remove_diagonal: Any = True \n",
      "\n",
      "\n",
      "class TFLossCosineSimilarityConfig(TFLossBaseConfig, A, F, T, i, s, x):\n",
      "     \n",
      "\n",
      "\n",
      "class TFLossDiceConfig(TFLossBaseConfig, A, F, T, i, s, x):\n",
      "     \n",
      "\n",
      "\n",
      "class TFLossHuberConfig(TFLossBaseConfig):\n",
      "    delta: Any = 1.0 \n",
      "\n",
      "\n",
      "class TFLossSparseCategoricalCrossentropyConfig(TFLossBaseConfig, TFLogits):\n",
      "    ignore_class: Any = None \n",
      "\n",
      "\n",
      "class TFLossTverskyConfig(TFLossBaseConfig, TFAxis):\n",
      "    alpha: Any = 0.5\n",
      "    beta: Any = 0.5 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_tf_loss_config_definitions():\n",
    "    def get_base_class(data, arg, class_, base_class):\n",
    "        mask = data.arg.apply(lambda x: x == arg)\n",
    "        temp = data[mask]\n",
    "        result = get_class_definitions(temp, base_class)[0]\n",
    "        result = re.sub('class TF[a-zA-Z]*Config', f'class {class_}', result)\n",
    "        return result\n",
    "    \n",
    "    def get_tf_class_definition(class_, inherit, signature):\n",
    "        inherit = ', '.join(sorted(filter(lambda x: x != '', inherit)))\n",
    "        output = f'class TFLoss{class_}Config(TFLossBaseConfig, {inherit}):\\n    '\n",
    "        output = re.sub(', \\)', ')', output)\n",
    "        regex = '(axis|from_logits):'\n",
    "        if not isinstance(signature, np.ndarray):\n",
    "            signature = [signature]\n",
    "        signature = list(filter(lambda x: not re.search(regex, x), signature))\n",
    "        output +=  '\\n    '.join(sorted(signature))\n",
    "        return output\n",
    "\n",
    "    # TF\n",
    "    data = get_loss_data()\n",
    "    mask = data.library == 'tf'\n",
    "    data = data[mask]\n",
    "\n",
    "    # TFLossBaseConfig\n",
    "    args = [\n",
    "        'name',\n",
    "        'dtype',\n",
    "        'reduction',\n",
    "    ]\n",
    "    mask = data.arg.apply(lambda x: x in args)\n",
    "    d0 = data[mask]\n",
    "    tf_base = get_class_definitions(d0)[0]\n",
    "    tf_base = re.sub('TF[a-zA-Z]*Config', 'TFLossBaseConfig', tf_base)\n",
    "    print(tf_base, '\\n\\n')    \n",
    "    \n",
    "    # aux base configs\n",
    "    lut = [\n",
    "        ('axis', 'TFAxis'),\n",
    "        ('from_logits', 'TFLogits'),\n",
    "    ]\n",
    "    data['inherit'] = ''\n",
    "    for arg, cls_ in lut:\n",
    "        print(get_base_class(data, arg, cls_, 'TFLossBaseConfig'), '\\n\\n')\n",
    "        mask = data.arg == arg\n",
    "        data.loc[mask, 'inherit'] = cls_\n",
    "    \n",
    "    # classes\n",
    "    mask = data.arg.apply(lambda x: x not in args)\n",
    "    d1 = data[mask]\n",
    "    \n",
    "    class_def = d1 \\\n",
    "        .groupby('class_', as_index=False)[['inherit', 'signature']] \\\n",
    "        .agg(lambda x: x) \\\n",
    "        .apply(lambda x: get_tf_class_definition(x.class_, x.inherit, x.signature), axis=1) \\\n",
    "        .tolist()  \n",
    "    for item in class_def:\n",
    "        print(item, '\\n\\n')\n",
    "        \n",
    "print_tf_loss_config_definitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "86071452-7aff-4ebd-ae4a-aa46adc15b9e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = get_optimizer_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d0f9b2ac-ea8e-493e-a650-c9724afc0ccc",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adadelta</th>\n",
       "      <th>Adafactor</th>\n",
       "      <th>Adagrad</th>\n",
       "      <th>Adam</th>\n",
       "      <th>AdamW</th>\n",
       "      <th>Adamax</th>\n",
       "      <th>Ftrl</th>\n",
       "      <th>Lamb</th>\n",
       "      <th>Lion</th>\n",
       "      <th>Nadam</th>\n",
       "      <th>RMSprop</th>\n",
       "      <th>SGD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clipnorm</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clipvalue</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ema_momentum</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ema_overwrite_frequency</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_clipnorm</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gradient_accumulation_steps</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_scale_factor</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_ema</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_decay</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epsilon</th>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amsgrad</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial_accumulator_value</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>momentum</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rho</th>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_2_decay</th>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>centered</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clip_threshold</th>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epsilon_1</th>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epsilon_2</th>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_regularization_strength</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2_regularization_strength</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2_shrinkage_regularization_strength</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate_power</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nesterov</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative_step</th>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Adadelta Adafactor Adagrad Adam AdamW  \\\n",
       "clipnorm                                    x         x       x    x     x   \n",
       "clipvalue                                   x         x       x    x     x   \n",
       "ema_momentum                                x         x       x    x     x   \n",
       "ema_overwrite_frequency                     x         x       x    x     x   \n",
       "global_clipnorm                             x         x       x    x     x   \n",
       "gradient_accumulation_steps                 x         x       x    x     x   \n",
       "learning_rate                               x         x       x    x     x   \n",
       "loss_scale_factor                           x         x       x    x     x   \n",
       "name                                        x         x       x    x     x   \n",
       "use_ema                                     x         x       x    x     x   \n",
       "weight_decay                                x         x       x    x     x   \n",
       "epsilon                                     x                 x    x     x   \n",
       "beta_1                                                             x     x   \n",
       "beta_2                                                             x     x   \n",
       "amsgrad                                                            x     x   \n",
       "initial_accumulator_value                                     x              \n",
       "momentum                                                                     \n",
       "rho                                         x                                \n",
       "beta                                                                         \n",
       "beta_2_decay                                          x                      \n",
       "centered                                                                     \n",
       "clip_threshold                                        x                      \n",
       "epsilon_1                                             x                      \n",
       "epsilon_2                                             x                      \n",
       "l1_regularization_strength                                                   \n",
       "l2_regularization_strength                                                   \n",
       "l2_shrinkage_regularization_strength                                         \n",
       "learning_rate_power                                                          \n",
       "nesterov                                                                     \n",
       "relative_step                                         x                      \n",
       "\n",
       "                                     Adamax Ftrl Lamb Lion Nadam RMSprop SGD  \n",
       "clipnorm                                  x    x    x    x     x       x   x  \n",
       "clipvalue                                 x    x    x    x     x       x   x  \n",
       "ema_momentum                              x    x    x    x     x       x   x  \n",
       "ema_overwrite_frequency                   x    x    x    x     x       x   x  \n",
       "global_clipnorm                           x    x    x    x     x       x   x  \n",
       "gradient_accumulation_steps               x    x    x    x     x       x   x  \n",
       "learning_rate                             x    x    x    x     x       x   x  \n",
       "loss_scale_factor                         x    x    x    x     x       x   x  \n",
       "name                                      x    x    x    x     x       x   x  \n",
       "use_ema                                   x    x    x    x     x       x   x  \n",
       "weight_decay                              x    x    x    x     x       x   x  \n",
       "epsilon                                   x         x          x       x      \n",
       "beta_1                                    x         x    x     x              \n",
       "beta_2                                    x         x    x     x              \n",
       "amsgrad                                                                       \n",
       "initial_accumulator_value                      x                              \n",
       "momentum                                                               x   x  \n",
       "rho                                                                    x      \n",
       "beta                                           x                              \n",
       "beta_2_decay                                                                  \n",
       "centered                                                               x      \n",
       "clip_threshold                                                                \n",
       "epsilon_1                                                                     \n",
       "epsilon_2                                                                     \n",
       "l1_regularization_strength                     x                              \n",
       "l2_regularization_strength                     x                              \n",
       "l2_shrinkage_regularization_strength           x                              \n",
       "learning_rate_power                            x                              \n",
       "nesterov                                                                   x  \n",
       "relative_step                                                                 "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_comparison_checkboxes(data, 'tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b839de69-868b-4eff-b548-b234a7499552",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASGD</th>\n",
       "      <th>Adadelta</th>\n",
       "      <th>Adafactor</th>\n",
       "      <th>Adagrad</th>\n",
       "      <th>Adam</th>\n",
       "      <th>AdamW</th>\n",
       "      <th>Adamax</th>\n",
       "      <th>LBFGS</th>\n",
       "      <th>NAdam</th>\n",
       "      <th>RAdam</th>\n",
       "      <th>RMSprop</th>\n",
       "      <th>Rprop</th>\n",
       "      <th>SGD</th>\n",
       "      <th>SparseAdam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximize</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foreach</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>differentiable</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_decay</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eps</th>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capturable</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>betas</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fused</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amsgrad</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoupled_weight_decay</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>momentum</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta2_decay</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>centered</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dampening</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>etas</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>history_size</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial_accumulator_value</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lambd</th>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_search_fn</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_decay</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_eval</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_iter</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>momentum_decay</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nesterov</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rho</th>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>step_sizes</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t0</th>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tolerance_change</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tolerance_grad</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          ASGD Adadelta Adafactor Adagrad Adam AdamW Adamax  \\\n",
       "lr                           x        x         x       x    x     x      x   \n",
       "maximize                     x        x         x       x    x     x      x   \n",
       "foreach                      x        x         x       x    x     x      x   \n",
       "differentiable               x        x                 x    x     x      x   \n",
       "weight_decay                 x        x         x       x    x     x      x   \n",
       "eps                                   x         x       x    x     x      x   \n",
       "capturable                   x        x                      x     x      x   \n",
       "betas                                                        x     x      x   \n",
       "fused                                                   x    x     x          \n",
       "alpha                        x                                                \n",
       "amsgrad                                                      x     x          \n",
       "decoupled_weight_decay                                                        \n",
       "momentum                                                                      \n",
       "beta2_decay                                     x                             \n",
       "centered                                                                      \n",
       "d                                               x                             \n",
       "dampening                                                                     \n",
       "etas                                                                          \n",
       "history_size                                                                  \n",
       "initial_accumulator_value                               x                     \n",
       "lambd                        x                                                \n",
       "line_search_fn                                                                \n",
       "lr_decay                                                x                     \n",
       "max_eval                                                                      \n",
       "max_iter                                                                      \n",
       "momentum_decay                                                                \n",
       "nesterov                                                                      \n",
       "rho                                   x                                       \n",
       "step_sizes                                                                    \n",
       "t0                           x                                                \n",
       "tolerance_change                                                              \n",
       "tolerance_grad                                                                \n",
       "\n",
       "                          LBFGS NAdam RAdam RMSprop Rprop SGD SparseAdam  \n",
       "lr                            x     x     x       x     x   x          x  \n",
       "maximize                            x     x       x     x   x          x  \n",
       "foreach                             x     x       x     x   x             \n",
       "differentiable                      x     x       x     x   x             \n",
       "weight_decay                        x     x       x         x             \n",
       "eps                                 x     x       x                    x  \n",
       "capturable                          x     x       x     x                 \n",
       "betas                               x     x                            x  \n",
       "fused                                                       x             \n",
       "alpha                                             x                       \n",
       "amsgrad                                                                   \n",
       "decoupled_weight_decay              x     x                               \n",
       "momentum                                          x         x             \n",
       "beta2_decay                                                               \n",
       "centered                                          x                       \n",
       "d                                                                         \n",
       "dampening                                                   x             \n",
       "etas                                                    x                 \n",
       "history_size                  x                                           \n",
       "initial_accumulator_value                                                 \n",
       "lambd                                                                     \n",
       "line_search_fn                x                                           \n",
       "lr_decay                                                                  \n",
       "max_eval                      x                                           \n",
       "max_iter                      x                                           \n",
       "momentum_decay                      x                                     \n",
       "nesterov                                                    x             \n",
       "rho                                                                       \n",
       "step_sizes                                              x                 \n",
       "t0                                                                        \n",
       "tolerance_change              x                                           \n",
       "tolerance_grad                x                                           "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_comparison_data(q, 'torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "c904975d-b584-40f2-b6c8-49668660cb01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dtype</th>\n",
       "      <th>name</th>\n",
       "      <th>reduction</th>\n",
       "      <th>axis</th>\n",
       "      <th>from_logits</th>\n",
       "      <th>label_smoothing</th>\n",
       "      <th>alpha</th>\n",
       "      <th>gamma</th>\n",
       "      <th>apply_class_balancing</th>\n",
       "      <th>beta</th>\n",
       "      <th>delta</th>\n",
       "      <th>ignore_class</th>\n",
       "      <th>margin</th>\n",
       "      <th>remove_diagonal</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BinaryCrossentropy</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BinaryFocalCrossentropy</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTC</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CategoricalCrossentropy</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CategoricalFocalCrossentropy</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CategoricalHinge</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Circle</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CosineSimilarity</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Dice</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Hinge</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Huber</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KLDivergence</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>LogCosh</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Loss</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MeanAbsoluteError</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MeanAbsolutePercentageError</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MeanSquaredError</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MeanSquaredLogarithmicError</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Poisson</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SparseCategoricalCrossentropy</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SquaredHinge</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Tversky</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              dtype name reduction axis from_logits  \\\n",
       "BinaryCrossentropy                x    x         x    x           x   \n",
       "BinaryFocalCrossentropy           x    x         x    x           x   \n",
       "CTC                               x    x         x                    \n",
       "CategoricalCrossentropy           x    x         x    x           x   \n",
       "CategoricalFocalCrossentropy      x    x         x    x           x   \n",
       "CategoricalHinge                  x    x         x                    \n",
       "Circle                            x    x         x                    \n",
       "CosineSimilarity                  x    x         x    x               \n",
       "Dice                              x    x         x    x               \n",
       "Hinge                             x    x         x                    \n",
       "Huber                             x    x         x                    \n",
       "KLDivergence                      x    x         x                    \n",
       "LogCosh                           x    x         x                    \n",
       "Loss                              x    x         x                    \n",
       "MeanAbsoluteError                 x    x         x                    \n",
       "MeanAbsolutePercentageError       x    x         x                    \n",
       "MeanSquaredError                  x    x         x                    \n",
       "MeanSquaredLogarithmicError       x    x         x                    \n",
       "Poisson                           x    x         x                    \n",
       "SparseCategoricalCrossentropy     x    x         x                x   \n",
       "SquaredHinge                      x    x         x                    \n",
       "Tversky                           x    x         x    x               \n",
       "\n",
       "                              label_smoothing alpha gamma  \\\n",
       "BinaryCrossentropy                          x               \n",
       "BinaryFocalCrossentropy                     x     x     x   \n",
       "CTC                                                         \n",
       "CategoricalCrossentropy                     x               \n",
       "CategoricalFocalCrossentropy                x     x     x   \n",
       "CategoricalHinge                                            \n",
       "Circle                                                  x   \n",
       "CosineSimilarity                                            \n",
       "Dice                                                        \n",
       "Hinge                                                       \n",
       "Huber                                                       \n",
       "KLDivergence                                                \n",
       "LogCosh                                                     \n",
       "Loss                                                        \n",
       "MeanAbsoluteError                                           \n",
       "MeanAbsolutePercentageError                                 \n",
       "MeanSquaredError                                            \n",
       "MeanSquaredLogarithmicError                                 \n",
       "Poisson                                                     \n",
       "SparseCategoricalCrossentropy                               \n",
       "SquaredHinge                                                \n",
       "Tversky                                           x         \n",
       "\n",
       "                              apply_class_balancing beta delta ignore_class  \\\n",
       "BinaryCrossentropy                                                            \n",
       "BinaryFocalCrossentropy                           x                           \n",
       "CTC                                                                           \n",
       "CategoricalCrossentropy                                                       \n",
       "CategoricalFocalCrossentropy                                                  \n",
       "CategoricalHinge                                                              \n",
       "Circle                                                                        \n",
       "CosineSimilarity                                                              \n",
       "Dice                                                                          \n",
       "Hinge                                                                         \n",
       "Huber                                                        x                \n",
       "KLDivergence                                                                  \n",
       "LogCosh                                                                       \n",
       "Loss                                                                          \n",
       "MeanAbsoluteError                                                             \n",
       "MeanAbsolutePercentageError                                                   \n",
       "MeanSquaredError                                                              \n",
       "MeanSquaredLogarithmicError                                                   \n",
       "Poisson                                                                       \n",
       "SparseCategoricalCrossentropy                                             x   \n",
       "SquaredHinge                                                                  \n",
       "Tversky                                                x                      \n",
       "\n",
       "                              margin remove_diagonal  \n",
       "BinaryCrossentropy                                    \n",
       "BinaryFocalCrossentropy                               \n",
       "CTC                                                   \n",
       "CategoricalCrossentropy                               \n",
       "CategoricalFocalCrossentropy                          \n",
       "CategoricalHinge                                      \n",
       "Circle                             x               x  \n",
       "CosineSimilarity                                      \n",
       "Dice                                                  \n",
       "Hinge                                                 \n",
       "Huber                                                 \n",
       "KLDivergence                                          \n",
       "LogCosh                                               \n",
       "Loss                                                  \n",
       "MeanAbsoluteError                                     \n",
       "MeanAbsolutePercentageError                           \n",
       "MeanSquaredError                                      \n",
       "MeanSquaredLogarithmicError                           \n",
       "Poisson                                               \n",
       "SparseCategoricalCrossentropy                         \n",
       "SquaredHinge                                          \n",
       "Tversky                                               "
      ]
     },
     "execution_count": 235,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_loss_data()\n",
    "data\n",
    "get_comparison_checkboxes(data, 'tf').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64edbd71-3381-4104-b7fb-d4d9cc23bd09",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "TFLossBaseConfig\n",
    "    name\n",
    "    dtype\n",
    "    reduction"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
