{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "4075517e-3967-403c-bff6-005582374c48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "import re\n",
    "\n",
    "from tensorflow import keras  # noqa: F401\n",
    "from keras import optimizers as tfoptim\n",
    "from keras import losses as tfloss\n",
    "\n",
    "import torch\n",
    "import torch.optim as torchoptim\n",
    "import torch.nn.modules.loss as torchloss\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "\n",
    "import flatiron.core.tools as fict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "db3144b2-94d8-4baf-9d91-1711572a1690",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_classes(module):\n",
    "    members = inspect.getmembers(module)\n",
    "    members = list(filter(lambda x: inspect.isclass(x[1]), members))\n",
    "    members = list(filter(lambda x: not x[0].startswith('_'), members))\n",
    "    classes = dict(members)\n",
    "    return classes\n",
    "\n",
    "def create_signature(arg, annotation, default):\n",
    "    if annotation == 'UNTYPED':\n",
    "        annotation = 'Any'\n",
    "    if default == 'REQUIRED':\n",
    "        default = ''\n",
    "    else:\n",
    "        default = f' = {default}'\n",
    "    return f'{arg}: {annotation}{default}'\n",
    "\n",
    "def get_init_signature_data(class_, remove=['self']):\n",
    "    sig = inspect.getfullargspec(class_)\n",
    "    args = sig.args\n",
    "    for item in remove:\n",
    "        args.remove(item)\n",
    "\n",
    "    if sig.defaults is not None:\n",
    "        d = len(args) - len(sig.defaults)\n",
    "        req = args[:d]\n",
    "        opt = args[d:]\n",
    "        args = {k: 'REQUIRED' for k in req}\n",
    "        opt = dict(zip(opt, sig.defaults))\n",
    "        args.update(opt)\n",
    "    else:\n",
    "        args = {k: 'REQUIRED' for k in args}\n",
    "    \n",
    "    if isinstance(sig.kwonlydefaults, dict):\n",
    "        args.update(sig.kwonlydefaults)\n",
    "    \n",
    "    anno = sig.annotations\n",
    "    for key, val in args.items():\n",
    "        if key in anno:\n",
    "            args[key] = (val, anno[key].__name__)\n",
    "        else:\n",
    "            args[key] = (val, 'UNTYPED')\n",
    "            \n",
    "    data = []\n",
    "    for arg, (default, type_) in args.items():\n",
    "        data.append(dict(\n",
    "            arg=arg,\n",
    "            default=default,\n",
    "            type_=type_,\n",
    "            signature=create_signature(arg, type_, default),\n",
    "        ))\n",
    "    return data\n",
    "\n",
    "def get_module_class_data(module):\n",
    "    classes = get_classes(module)\n",
    "    data = []\n",
    "    for name, item in classes.items():\n",
    "        try:\n",
    "            datum = get_init_signature_data(item)\n",
    "        except:\n",
    "            continue\n",
    "        for row in datum:\n",
    "            row['class_'] = name\n",
    "        data.extend(datum)\n",
    "        \n",
    "    cols = ['class_', 'arg', 'type_', 'default', 'signature']\n",
    "    data = pd.DataFrame(data, columns=cols)\n",
    "    data['library'] = module.__name__.split('.')[0]\n",
    "    data['module'] = module.__name__\n",
    "    cols.insert(0, 'library')\n",
    "    cols.insert(1, 'module')\n",
    "    data = data[cols]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_optimizer_data():\n",
    "    tf_optim_data = get_module_class_data(tfoptim)\n",
    "    torch_optim_data = get_module_class_data(torchoptim)\n",
    "    data = pd.concat([tf_optim_data, torch_optim_data], axis=0)\n",
    "    \n",
    "    mask = data.library == 'keras'\n",
    "    data.loc[mask, 'library'] = 'tf'\n",
    "    \n",
    "    data['field'] = data['class_']\n",
    "    mask = data.field == 'Nadam'\n",
    "    data.loc[mask, 'field'] = 'NAdam'\n",
    "    \n",
    "    mask = data.class_.apply(lambda x: x not in ['Optimizer', 'LossScaleOptimizer'])\n",
    "    data = data[mask]\n",
    "    \n",
    "    mask = data.arg != 'params'\n",
    "    data = data[mask]\n",
    "\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_loss_data():\n",
    "    tf_loss_data = get_module_class_data(tfloss)\n",
    "    torch_loss_data = get_module_class_data(torchloss)\n",
    "    data = pd.concat([tf_loss_data, torch_loss_data], axis=0)\n",
    "    \n",
    "    mask = data.library == 'keras'\n",
    "    data.loc[mask, 'library'] = 'tf'\n",
    "    \n",
    "#     data['field'] = data['class_']\n",
    "#     mask = data.field == 'Nadam'\n",
    "#     data.loc[mask, 'field'] = 'NAdam'\n",
    "    \n",
    "#     mask = data.class_.apply(lambda x: x not in ['Optimizer', 'LossScaleOptimizer'])\n",
    "#     data = data[mask]\n",
    "    \n",
    "#     mask = data.arg != 'params'\n",
    "#     data = data[mask]\n",
    "\n",
    "#     data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_class_definitions(data, base_class='BaseConfig'):\n",
    "    data = data.copy()\n",
    "    data['config_name'] = data \\\n",
    "        .apply(lambda x: f'class {x.library.capitalize()}{x.class_}Config({base_class}):', axis=1) \\\n",
    "        .apply(lambda x: re.sub(' Tf', ' TF', x))\n",
    "    class_def = data.groupby('config_name', as_index=False).signature.agg(lambda x: '    ' + '\\n    '.join(sorted(x)))\n",
    "    class_def = class_def.apply(lambda x: f'{x.config_name}\\n{x.signature}', axis=1)\n",
    "    return class_def.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "d5db3018-d469-4d33-a2dd-44a5883ea480",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>library</th>\n",
       "      <th>module</th>\n",
       "      <th>class_</th>\n",
       "      <th>arg</th>\n",
       "      <th>type_</th>\n",
       "      <th>default</th>\n",
       "      <th>signature</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>tf</td>\n",
       "      <td>keras.api.losses</td>\n",
       "      <td>BinaryCrossentropy</td>\n",
       "      <td>from_logits</td>\n",
       "      <td>UNTYPED</td>\n",
       "      <td>False</td>\n",
       "      <td>from_logits: Any = False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>tf</td>\n",
       "      <td>keras.api.losses</td>\n",
       "      <td>BinaryCrossentropy</td>\n",
       "      <td>label_smoothing</td>\n",
       "      <td>UNTYPED</td>\n",
       "      <td>0.0</td>\n",
       "      <td>label_smoothing: Any = 0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>tf</td>\n",
       "      <td>keras.api.losses</td>\n",
       "      <td>BinaryCrossentropy</td>\n",
       "      <td>axis</td>\n",
       "      <td>UNTYPED</td>\n",
       "      <td>-1</td>\n",
       "      <td>axis: Any = -1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>tf</td>\n",
       "      <td>keras.api.losses</td>\n",
       "      <td>BinaryCrossentropy</td>\n",
       "      <td>reduction</td>\n",
       "      <td>UNTYPED</td>\n",
       "      <td>sum_over_batch_size</td>\n",
       "      <td>reduction: Any = sum_over_batch_size</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>tf</td>\n",
       "      <td>keras.api.losses</td>\n",
       "      <td>BinaryCrossentropy</td>\n",
       "      <td>name</td>\n",
       "      <td>UNTYPED</td>\n",
       "      <td>binary_crossentropy</td>\n",
       "      <td>name: Any = binary_crossentropy</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>88</th>\n",
       "      <td>torch</td>\n",
       "      <td>torch.nn.modules.loss</td>\n",
       "      <td>TripletMarginWithDistanceLoss</td>\n",
       "      <td>swap</td>\n",
       "      <td>bool</td>\n",
       "      <td>False</td>\n",
       "      <td>swap: bool = False</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>89</th>\n",
       "      <td>torch</td>\n",
       "      <td>torch.nn.modules.loss</td>\n",
       "      <td>TripletMarginWithDistanceLoss</td>\n",
       "      <td>reduction</td>\n",
       "      <td>str</td>\n",
       "      <td>mean</td>\n",
       "      <td>reduction: str = mean</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90</th>\n",
       "      <td>torch</td>\n",
       "      <td>torch.nn.modules.loss</td>\n",
       "      <td>deprecated</td>\n",
       "      <td>message</td>\n",
       "      <td>str</td>\n",
       "      <td>REQUIRED</td>\n",
       "      <td>message: str</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>91</th>\n",
       "      <td>torch</td>\n",
       "      <td>torch.nn.modules.loss</td>\n",
       "      <td>deprecated</td>\n",
       "      <td>category</td>\n",
       "      <td>Optional</td>\n",
       "      <td>&lt;class 'DeprecationWarning'&gt;</td>\n",
       "      <td>category: Optional = &lt;class 'DeprecationWarning'&gt;</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>92</th>\n",
       "      <td>torch</td>\n",
       "      <td>torch.nn.modules.loss</td>\n",
       "      <td>deprecated</td>\n",
       "      <td>stacklevel</td>\n",
       "      <td>int</td>\n",
       "      <td>1</td>\n",
       "      <td>stacklevel: int = 1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>187 rows × 7 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   library                 module                         class_  \\\n",
       "0       tf       keras.api.losses             BinaryCrossentropy   \n",
       "1       tf       keras.api.losses             BinaryCrossentropy   \n",
       "2       tf       keras.api.losses             BinaryCrossentropy   \n",
       "3       tf       keras.api.losses             BinaryCrossentropy   \n",
       "4       tf       keras.api.losses             BinaryCrossentropy   \n",
       "..     ...                    ...                            ...   \n",
       "88   torch  torch.nn.modules.loss  TripletMarginWithDistanceLoss   \n",
       "89   torch  torch.nn.modules.loss  TripletMarginWithDistanceLoss   \n",
       "90   torch  torch.nn.modules.loss                     deprecated   \n",
       "91   torch  torch.nn.modules.loss                     deprecated   \n",
       "92   torch  torch.nn.modules.loss                     deprecated   \n",
       "\n",
       "                arg     type_                       default  \\\n",
       "0       from_logits   UNTYPED                         False   \n",
       "1   label_smoothing   UNTYPED                           0.0   \n",
       "2              axis   UNTYPED                            -1   \n",
       "3         reduction   UNTYPED           sum_over_batch_size   \n",
       "4              name   UNTYPED           binary_crossentropy   \n",
       "..              ...       ...                           ...   \n",
       "88             swap      bool                         False   \n",
       "89        reduction       str                          mean   \n",
       "90          message       str                      REQUIRED   \n",
       "91         category  Optional  <class 'DeprecationWarning'>   \n",
       "92       stacklevel       int                             1   \n",
       "\n",
       "                                            signature  \n",
       "0                            from_logits: Any = False  \n",
       "1                          label_smoothing: Any = 0.0  \n",
       "2                                      axis: Any = -1  \n",
       "3                reduction: Any = sum_over_batch_size  \n",
       "4                     name: Any = binary_crossentropy  \n",
       "..                                                ...  \n",
       "88                                 swap: bool = False  \n",
       "89                              reduction: str = mean  \n",
       "90                                       message: str  \n",
       "91  category: Optional = <class 'DeprecationWarning'>  \n",
       "92                                stacklevel: int = 1  \n",
       "\n",
       "[187 rows x 7 columns]"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_loss_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "fc4d25f8-76e7-4713-89b3-6d21c667e0c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_tf_optimizer_config_definitions():\n",
    "    # TF\n",
    "    d = get_optimizer_data()\n",
    "    mask = d.library == 'tf'\n",
    "    d = d[mask]\n",
    "\n",
    "    # TFBaseConfig\n",
    "    tf_base_args = [\n",
    "        'clipnorm',\n",
    "        'clipvalue',\n",
    "        'ema_momentum',\n",
    "        'ema_overwrite_frequency',\n",
    "        'global_clipnorm',\n",
    "        'gradient_accumulation_steps',\n",
    "        'learning_rate',\n",
    "        'loss_scale_factor',\n",
    "        'name',\n",
    "        'use_ema',\n",
    "        'weight_decay',\n",
    "    ]\n",
    "    mask = d.arg.apply(lambda x: x in tf_base_args)\n",
    "    d0 = d[mask]\n",
    "    tf_base = get_class_definitions(d0)[0]\n",
    "    tf_base = re.sub('TFAdadeltaConfig', 'TFBaseConfig', tf_base)\n",
    "    print(tf_base, '\\n\\n')\n",
    "\n",
    "    # TFEpsilonBaseConfig\n",
    "    tf_eps_args = ['epsilon']\n",
    "    mask = d.arg.apply(lambda x: x in tf_eps_args)\n",
    "    d1 = d[mask]\n",
    "    tf_eps = get_class_definitions(d1, 'TFBaseConfig')[0]\n",
    "    tf_eps = re.sub('class TF[a-zA-Z]*Config', 'class TFEpsilonBaseConfig', tf_eps)\n",
    "    print(tf_eps, '\\n\\n')\n",
    "    \n",
    "    # TFEpsilonBaseConfig\n",
    "    tf_eps_args = ['epsilon']\n",
    "    mask = d.arg.apply(lambda x: x in tf_eps_args)\n",
    "    d1 = d[mask]\n",
    "    tf_eps = get_class_definitions(d1, 'TFBaseConfig')[0]\n",
    "    tf_eps = re.sub('class TF[a-zA-Z]*Config', 'class TFEpsilonBaseConfig', tf_eps)\n",
    "    print(tf_eps, '\\n\\n')\n",
    "\n",
    "    # TFBaseConfig subclasses\n",
    "    eps_classes = d1.class_.unique().tolist()\n",
    "    mask = d.class_.apply(lambda x: x in eps_classes)\n",
    "    d2 = d[~mask]\n",
    "    mask = d2.arg.apply(lambda x: x in tf_base_args)\n",
    "    d2 = d2[~mask]\n",
    "    tf_subclass = get_class_definitions(d2, 'TFBaseConfig')\n",
    "    for item in tf_subclass:\n",
    "        print(item, '\\n\\n')\n",
    "\n",
    "    # TFEpsilonBaseConfig subclasses\n",
    "    eps_classes = d1.class_.unique().tolist()\n",
    "    mask = d.class_.apply(lambda x: x in eps_classes)\n",
    "    d2 = d[mask]\n",
    "    mask = d2.arg.apply(lambda x: x in tf_base_args or x in tf_eps_args)\n",
    "    d2 = d2[~mask]\n",
    "    tf_eps_subclass = get_class_definitions(d2, 'TFEpsilonBaseConfig')\n",
    "    for item in tf_eps_subclass:\n",
    "        print(item, '\\n\\n')\n",
    "\n",
    "\n",
    "def print_torch_optimizer_config_definitions():\n",
    "    def get_base_class(data, arg, class_, base_class):\n",
    "        mask = data.arg.apply(lambda x: x == arg)\n",
    "        temp = data[mask]\n",
    "        result = get_class_definitions(temp, base_class)[0]\n",
    "        result = re.sub('class Torch[a-zA-Z]*Config', f'class {class_}', result)\n",
    "        return result\n",
    "    \n",
    "    def get_torch_class_definition(class_, inherit, signature):\n",
    "        inherit = ', '.join(sorted(filter(lambda x: x != '', inherit)))\n",
    "        output = f'class Torch{class_}Config(TorchBaseConfig, {inherit}):\\n    '\n",
    "        output = re.sub(', \\)', ')', output)\n",
    "        regex = '(params|lr|maximize|foreach|differentiable|eps|capturable|weight_decay):'\n",
    "        signature = list(filter(lambda x: not re.search(regex, x), signature))\n",
    "        output +=  '\\n    '.join(sorted(signature))\n",
    "        return output\n",
    "\n",
    "    # Torch\n",
    "    data = get_optimizer_data()\n",
    "    mask = data.library == 'torch'\n",
    "    data = data[mask]\n",
    "\n",
    "    # TFBaseConfig\n",
    "    mask = data.arg.apply(lambda x: x == 'lr')\n",
    "    d0 = data[mask]\n",
    "    torch_base = get_class_definitions(d0)[0]\n",
    "    torch_base = re.sub('TorchASGDConfig', 'TorchBaseConfig', torch_base)\n",
    "    print(torch_base, '\\n\\n')    \n",
    "    \n",
    "    # aux base configs\n",
    "    lut = [\n",
    "        ('maximize', 'TMax'),\n",
    "        ('foreach', 'TFor'),\n",
    "        ('differentiable', 'TDiff'),\n",
    "        ('eps', 'TEps'),\n",
    "        ('capturable', 'TCap'),\n",
    "        ('weight_decay', 'TDecay'),\n",
    "    ]\n",
    "    data['inherit'] = ''\n",
    "    for arg, cls_ in lut:\n",
    "        print(get_base_class(data, arg, cls_, 'TorchBaseConfig'), '\\n\\n')\n",
    "        mask = data.arg == arg\n",
    "        data.loc[mask, 'inherit'] = cls_\n",
    "    \n",
    "    # classes\n",
    "    class_def = data \\\n",
    "        .sort_values('class_') \\\n",
    "        .groupby('class_', as_index=False)[['inherit', 'signature']] \\\n",
    "        .agg(lambda x: x) \\\n",
    "        .apply(lambda x: get_torch_class_definition(x.class_, x.inherit, x.signature), axis=1) \\\n",
    "        .tolist()  \n",
    "    for item in class_def:\n",
    "        print(item, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "6f7b1755-b094-4b47-8850-658ccfc756e1",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class TFBaseConfig(BaseConfig):\n",
      "    clipnorm: Any = None\n",
      "    clipvalue: Any = None\n",
      "    ema_momentum: Any = 0.99\n",
      "    ema_overwrite_frequency: Any = None\n",
      "    global_clipnorm: Any = None\n",
      "    gradient_accumulation_steps: Any = None\n",
      "    learning_rate: Any = 0.001\n",
      "    loss_scale_factor: Any = None\n",
      "    name: Any = adadelta\n",
      "    use_ema: Any = False\n",
      "    weight_decay: Any = None \n",
      "\n",
      "\n",
      "class TFEps(TFBaseConfig):\n",
      "    epsilon: Any = 1e-07 \n",
      "\n",
      "\n",
      "class TFBeta(TFBaseConfig):\n",
      "    beta_1: Any = 0.9 \n",
      "\n",
      "\n",
      "class TFAdadeltaConfig(TFBaseConfig, TFEps):\n",
      "    rho: Any = 0.95 \n",
      "\n",
      "\n",
      "class TFAdafactorConfig(TFBaseConfig):\n",
      "    beta_2_decay: Any = -0.8\n",
      "    clip_threshold: Any = 1.0\n",
      "    epsilon_1: Any = 1e-30\n",
      "    epsilon_2: Any = 0.001\n",
      "    relative_step: Any = True \n",
      "\n",
      "\n",
      "class TFAdagradConfig(TFBaseConfig, TFEps):\n",
      "    initial_accumulator_value: Any = 0.1 \n",
      "\n",
      "\n",
      "class TFAdamConfig(TFBaseConfig, TFBeta, TFEps):\n",
      "    amsgrad: Any = False \n",
      "\n",
      "\n",
      "class TFAdamWConfig(TFBaseConfig, TFBeta, TFEps):\n",
      "    amsgrad: Any = False \n",
      "\n",
      "\n",
      "class TFAdamaxConfig(TFBaseConfig, TFBeta, TFEps):\n",
      "     \n",
      "\n",
      "\n",
      "class TFFtrlConfig(TFBaseConfig):\n",
      "    beta: Any = 0.0\n",
      "    initial_accumulator_value: Any = 0.1\n",
      "    l1_regularization_strength: Any = 0.0\n",
      "    l2_regularization_strength: Any = 0.0\n",
      "    l2_shrinkage_regularization_strength: Any = 0.0\n",
      "    learning_rate_power: Any = -0.5 \n",
      "\n",
      "\n",
      "class TFLambConfig(TFBaseConfig, TFBeta, TFEps):\n",
      "     \n",
      "\n",
      "\n",
      "class TFLionConfig(TFBaseConfig, TFBeta):\n",
      "     \n",
      "\n",
      "\n",
      "class TFNadamConfig(TFBaseConfig, TFBeta, TFEps):\n",
      "     \n",
      "\n",
      "\n",
      "class TFRMSpropConfig(TFBaseConfig, TFEps):\n",
      "    centered: Any = False\n",
      "    momentum: Any = 0.0\n",
      "    rho: Any = 0.9 \n",
      "\n",
      "\n",
      "class TFSGDConfig(TFBaseConfig):\n",
      "    momentum: Any = 0.0\n",
      "    nesterov: Any = False \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "def print_tf_optimizer_config_definitions():\n",
    "    def get_base_class(data, arg, class_, base_class):\n",
    "        mask = data.arg.apply(lambda x: x == arg)\n",
    "        temp = data[mask]\n",
    "        result = get_class_definitions(temp, base_class)[0]\n",
    "        result = re.sub('class TF[a-zA-Z]*Config', f'class {class_}', result)\n",
    "        return result\n",
    "    \n",
    "    def get_tf_class_definition(class_, inherit, signature):\n",
    "        inherit = ', '.join(sorted(filter(lambda x: x != '', inherit)))\n",
    "        output = f'class TF{class_}Config(TFBaseConfig, {inherit}):\\n    '\n",
    "        output = re.sub(', \\)', ')', output)\n",
    "        regex = '(epsilon|beta_1|beta_2):'\n",
    "        signature = list(filter(lambda x: not re.search(regex, x), signature))\n",
    "        output +=  '\\n    '.join(sorted(signature))\n",
    "        return output\n",
    "\n",
    "    # TF\n",
    "    data = get_optimizer_data()\n",
    "    mask = data.library == 'tf'\n",
    "    data = data[mask]\n",
    "\n",
    "    # TFBaseConfig\n",
    "    args = [\n",
    "        'clipnorm',\n",
    "        'clipvalue',\n",
    "        'ema_momentum',\n",
    "        'ema_overwrite_frequency',\n",
    "        'global_clipnorm',\n",
    "        'gradient_accumulation_steps',\n",
    "        'learning_rate',\n",
    "        'loss_scale_factor',\n",
    "        'name',\n",
    "        'use_ema',\n",
    "        'weight_decay',\n",
    "    ]\n",
    "    mask = data.arg.apply(lambda x: x in args)\n",
    "    d0 = data[mask]\n",
    "    tf_base = get_class_definitions(d0)[0]\n",
    "    tf_base = re.sub('TF[a-zA-Z]*Config', 'TFBaseConfig', tf_base)\n",
    "    print(tf_base, '\\n\\n')    \n",
    "    \n",
    "    # aux base configs\n",
    "    lut = [\n",
    "        ('epsilon', 'TFEps'),\n",
    "        ('beta_1', 'TFBeta'),\n",
    "    ]\n",
    "    data['inherit'] = ''\n",
    "    for arg, cls_ in lut:\n",
    "        print(get_base_class(data, arg, cls_, 'TFBaseConfig'), '\\n\\n')\n",
    "        mask = data.arg == arg\n",
    "        data.loc[mask, 'inherit'] = cls_\n",
    "    \n",
    "    # classes\n",
    "    mask = data.arg.apply(lambda x: x not in args)\n",
    "    d1 = data[mask]\n",
    "    class_def = d1 \\\n",
    "        .groupby('class_', as_index=False)[['inherit', 'signature']] \\\n",
    "        .agg(lambda x: x) \\\n",
    "        .apply(lambda x: get_tf_class_definition(x.class_, x.inherit, x.signature), axis=1) \\\n",
    "        .tolist()  \n",
    "    for item in class_def:\n",
    "        print(item, '\\n\\n')\n",
    "        \n",
    "print_tf_optimizer_config_definitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "f0d4c322-6b9b-4f8f-b7d0-40809ee41913",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "class TFBaseConfig(BaseConfig):\n",
      "    clipnorm: Any = None\n",
      "    clipvalue: Any = None\n",
      "    ema_momentum: Any = 0.99\n",
      "    ema_overwrite_frequency: Any = None\n",
      "    global_clipnorm: Any = None\n",
      "    gradient_accumulation_steps: Any = None\n",
      "    learning_rate: Any = 0.001\n",
      "    loss_scale_factor: Any = None\n",
      "    name: Any = adadelta\n",
      "    use_ema: Any = False\n",
      "    weight_decay: Any = None \n",
      "\n",
      "\n",
      "class TFEpsilonBaseConfig(TFBaseConfig):\n",
      "    epsilon: Any = 1e-07 \n",
      "\n",
      "\n",
      "class TFEpsilonBaseConfig(TFBaseConfig):\n",
      "    epsilon: Any = 1e-07 \n",
      "\n",
      "\n",
      "class TFAdafactorConfig(TFBaseConfig):\n",
      "    beta_2_decay: Any = -0.8\n",
      "    clip_threshold: Any = 1.0\n",
      "    epsilon_1: Any = 1e-30\n",
      "    epsilon_2: Any = 0.001\n",
      "    relative_step: Any = True \n",
      "\n",
      "\n",
      "class TFFtrlConfig(TFBaseConfig):\n",
      "    beta: Any = 0.0\n",
      "    initial_accumulator_value: Any = 0.1\n",
      "    l1_regularization_strength: Any = 0.0\n",
      "    l2_regularization_strength: Any = 0.0\n",
      "    l2_shrinkage_regularization_strength: Any = 0.0\n",
      "    learning_rate_power: Any = -0.5 \n",
      "\n",
      "\n",
      "class TFLionConfig(TFBaseConfig):\n",
      "    beta_1: Any = 0.9\n",
      "    beta_2: Any = 0.99 \n",
      "\n",
      "\n",
      "class TFSGDConfig(TFBaseConfig):\n",
      "    momentum: Any = 0.0\n",
      "    nesterov: Any = False \n",
      "\n",
      "\n",
      "class TFAdadeltaConfig(TFEpsilonBaseConfig):\n",
      "    rho: Any = 0.95 \n",
      "\n",
      "\n",
      "class TFAdagradConfig(TFEpsilonBaseConfig):\n",
      "    initial_accumulator_value: Any = 0.1 \n",
      "\n",
      "\n",
      "class TFAdamConfig(TFEpsilonBaseConfig):\n",
      "    amsgrad: Any = False\n",
      "    beta_1: Any = 0.9\n",
      "    beta_2: Any = 0.999 \n",
      "\n",
      "\n",
      "class TFAdamWConfig(TFEpsilonBaseConfig):\n",
      "    amsgrad: Any = False\n",
      "    beta_1: Any = 0.9\n",
      "    beta_2: Any = 0.999 \n",
      "\n",
      "\n",
      "class TFAdamaxConfig(TFEpsilonBaseConfig):\n",
      "    beta_1: Any = 0.9\n",
      "    beta_2: Any = 0.999 \n",
      "\n",
      "\n",
      "class TFLambConfig(TFEpsilonBaseConfig):\n",
      "    beta_1: Any = 0.9\n",
      "    beta_2: Any = 0.999 \n",
      "\n",
      "\n",
      "class TFNadamConfig(TFEpsilonBaseConfig):\n",
      "    beta_1: Any = 0.9\n",
      "    beta_2: Any = 0.999 \n",
      "\n",
      "\n",
      "class TFRMSpropConfig(TFEpsilonBaseConfig):\n",
      "    centered: Any = False\n",
      "    momentum: Any = 0.0\n",
      "    rho: Any = 0.9 \n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print_tf_optimizer_config_definitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "a60c6488-24c9-4a6f-bb95-c9f222498b8d",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "print_torch_optimizer_config_definitions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "dd65c25f-6c16-423b-9fdf-467e4a883cbe",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_tf_loss_config_definitions():\n",
    "    # TF\n",
    "    d = get_loss_data()\n",
    "    mask = d.library == 'tf'\n",
    "    d = d[mask]\n",
    "\n",
    "    # TFBaseConfig\n",
    "    tf_base_args = [\n",
    "        'clipnorm',\n",
    "        'clipvalue',\n",
    "        'ema_momentum',\n",
    "        'ema_overwrite_frequency',\n",
    "        'global_clipnorm',\n",
    "        'gradient_accumulation_steps',\n",
    "        'learning_rate',\n",
    "        'loss_scale_factor',\n",
    "        'name',\n",
    "        'use_ema',\n",
    "        'weight_decay',\n",
    "    ]\n",
    "    mask = d.arg.apply(lambda x: x in tf_base_args)\n",
    "    d0 = d[mask]\n",
    "    tf_base = get_class_definitions(d0)[0]\n",
    "    tf_base = re.sub('TFAdadeltaConfig', 'TFBaseConfig', tf_base)\n",
    "    print(tf_base, '\\n\\n')\n",
    "\n",
    "    # TFEpsilonBaseConfig\n",
    "    tf_eps_args = ['epsilon']\n",
    "    mask = d.arg.apply(lambda x: x in tf_eps_args)\n",
    "    d1 = d[mask]\n",
    "    tf_eps = get_class_definitions(d1, 'TFBaseConfig')[0]\n",
    "    tf_eps = re.sub('TFAdadeltaConfig', 'TFEpsilonBaseConfig', tf_eps)\n",
    "    print(tf_eps, '\\n\\n')\n",
    "\n",
    "    # TFBaseConfig subclasses\n",
    "    eps_classes = d1.class_.unique().tolist()\n",
    "    mask = d.class_.apply(lambda x: x in eps_classes)\n",
    "    d2 = d[~mask]\n",
    "    mask = d2.arg.apply(lambda x: x in tf_base_args)\n",
    "    d2 = d2[~mask]\n",
    "    tf_subclass = get_class_definitions(d2, 'TFBaseConfig')\n",
    "    for item in tf_subclass:\n",
    "        print(item, '\\n\\n')\n",
    "\n",
    "    # TFEpsilonBaseConfig subclasses\n",
    "    eps_classes = d1.class_.unique().tolist()\n",
    "    mask = d.class_.apply(lambda x: x in eps_classes)\n",
    "    d2 = d[mask]\n",
    "    mask = d2.arg.apply(lambda x: x in tf_base_args or x in tf_eps_args)\n",
    "    d2 = d2[~mask]\n",
    "    tf_eps_subclass = get_class_definitions(d2, 'TFEpsilonBaseConfig')\n",
    "    for item in tf_eps_subclass:\n",
    "        print(item, '\\n\\n')\n",
    "        \n",
    "def get_comparison_data(data, mask=None):\n",
    "    data = data.copy()\n",
    "    if mask is not None:\n",
    "        mask = data.library == mask\n",
    "        data = data[mask]\n",
    "    data = data.groupby('arg', as_index=False)[['library', 'class_']].agg(lambda x: x.unique())\n",
    "    data['len_library'] = data.library.apply(len)\n",
    "    data['len_class'] = data.class_.apply(len)\n",
    "    data.sort_values(['len_class', 'len_library'], ascending=False, inplace=True)\n",
    "    return data\n",
    "\n",
    "def get_comparison_checkboxes(data, mask=None):\n",
    "    data = get_comparison_data(data, mask=mask)\n",
    "    output = data.class_.apply(lambda x: {k: k for k in x}).tolist()\n",
    "    index = data.arg.tolist()\n",
    "    output = pd.DataFrame(output, index=index).map(lambda x: '' if pd.isnull(x) else 'x')\n",
    "    return output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "86071452-7aff-4ebd-ae4a-aa46adc15b9e",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = get_optimizer_data()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "d0f9b2ac-ea8e-493e-a650-c9724afc0ccc",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Adadelta</th>\n",
       "      <th>Adafactor</th>\n",
       "      <th>Adagrad</th>\n",
       "      <th>Adam</th>\n",
       "      <th>AdamW</th>\n",
       "      <th>Adamax</th>\n",
       "      <th>Ftrl</th>\n",
       "      <th>Lamb</th>\n",
       "      <th>Lion</th>\n",
       "      <th>Nadam</th>\n",
       "      <th>RMSprop</th>\n",
       "      <th>SGD</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>clipnorm</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clipvalue</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ema_momentum</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>ema_overwrite_frequency</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>global_clipnorm</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gradient_accumulation_steps</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>loss_scale_factor</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>name</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>use_ema</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_decay</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epsilon</th>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_1</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_2</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amsgrad</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial_accumulator_value</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>momentum</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rho</th>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta_2_decay</th>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>centered</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>clip_threshold</th>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epsilon_1</th>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>epsilon_2</th>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l1_regularization_strength</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2_regularization_strength</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>l2_shrinkage_regularization_strength</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>learning_rate_power</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nesterov</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>relative_step</th>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                     Adadelta Adafactor Adagrad Adam AdamW  \\\n",
       "clipnorm                                    x         x       x    x     x   \n",
       "clipvalue                                   x         x       x    x     x   \n",
       "ema_momentum                                x         x       x    x     x   \n",
       "ema_overwrite_frequency                     x         x       x    x     x   \n",
       "global_clipnorm                             x         x       x    x     x   \n",
       "gradient_accumulation_steps                 x         x       x    x     x   \n",
       "learning_rate                               x         x       x    x     x   \n",
       "loss_scale_factor                           x         x       x    x     x   \n",
       "name                                        x         x       x    x     x   \n",
       "use_ema                                     x         x       x    x     x   \n",
       "weight_decay                                x         x       x    x     x   \n",
       "epsilon                                     x                 x    x     x   \n",
       "beta_1                                                             x     x   \n",
       "beta_2                                                             x     x   \n",
       "amsgrad                                                            x     x   \n",
       "initial_accumulator_value                                     x              \n",
       "momentum                                                                     \n",
       "rho                                         x                                \n",
       "beta                                                                         \n",
       "beta_2_decay                                          x                      \n",
       "centered                                                                     \n",
       "clip_threshold                                        x                      \n",
       "epsilon_1                                             x                      \n",
       "epsilon_2                                             x                      \n",
       "l1_regularization_strength                                                   \n",
       "l2_regularization_strength                                                   \n",
       "l2_shrinkage_regularization_strength                                         \n",
       "learning_rate_power                                                          \n",
       "nesterov                                                                     \n",
       "relative_step                                         x                      \n",
       "\n",
       "                                     Adamax Ftrl Lamb Lion Nadam RMSprop SGD  \n",
       "clipnorm                                  x    x    x    x     x       x   x  \n",
       "clipvalue                                 x    x    x    x     x       x   x  \n",
       "ema_momentum                              x    x    x    x     x       x   x  \n",
       "ema_overwrite_frequency                   x    x    x    x     x       x   x  \n",
       "global_clipnorm                           x    x    x    x     x       x   x  \n",
       "gradient_accumulation_steps               x    x    x    x     x       x   x  \n",
       "learning_rate                             x    x    x    x     x       x   x  \n",
       "loss_scale_factor                         x    x    x    x     x       x   x  \n",
       "name                                      x    x    x    x     x       x   x  \n",
       "use_ema                                   x    x    x    x     x       x   x  \n",
       "weight_decay                              x    x    x    x     x       x   x  \n",
       "epsilon                                   x         x          x       x      \n",
       "beta_1                                    x         x    x     x              \n",
       "beta_2                                    x         x    x     x              \n",
       "amsgrad                                                                       \n",
       "initial_accumulator_value                      x                              \n",
       "momentum                                                               x   x  \n",
       "rho                                                                    x      \n",
       "beta                                           x                              \n",
       "beta_2_decay                                                                  \n",
       "centered                                                               x      \n",
       "clip_threshold                                                                \n",
       "epsilon_1                                                                     \n",
       "epsilon_2                                                                     \n",
       "l1_regularization_strength                     x                              \n",
       "l2_regularization_strength                     x                              \n",
       "l2_shrinkage_regularization_strength           x                              \n",
       "learning_rate_power                            x                              \n",
       "nesterov                                                                   x  \n",
       "relative_step                                                                 "
      ]
     },
     "execution_count": 140,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_comparison_checkboxes(data, 'tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "b839de69-868b-4eff-b548-b234a7499552",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ASGD</th>\n",
       "      <th>Adadelta</th>\n",
       "      <th>Adafactor</th>\n",
       "      <th>Adagrad</th>\n",
       "      <th>Adam</th>\n",
       "      <th>AdamW</th>\n",
       "      <th>Adamax</th>\n",
       "      <th>LBFGS</th>\n",
       "      <th>NAdam</th>\n",
       "      <th>RAdam</th>\n",
       "      <th>RMSprop</th>\n",
       "      <th>Rprop</th>\n",
       "      <th>SGD</th>\n",
       "      <th>SparseAdam</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>maximize</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>foreach</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>differentiable</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>weight_decay</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>eps</th>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>capturable</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>betas</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>fused</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>alpha</th>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>amsgrad</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>decoupled_weight_decay</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>momentum</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>beta2_decay</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>centered</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>d</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dampening</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>etas</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>history_size</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>initial_accumulator_value</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lambd</th>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>line_search_fn</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr_decay</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_eval</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max_iter</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>momentum_decay</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>nesterov</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>rho</th>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>step_sizes</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>t0</th>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tolerance_change</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>tolerance_grad</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                          ASGD Adadelta Adafactor Adagrad Adam AdamW Adamax  \\\n",
       "lr                           x        x         x       x    x     x      x   \n",
       "maximize                     x        x         x       x    x     x      x   \n",
       "foreach                      x        x         x       x    x     x      x   \n",
       "differentiable               x        x                 x    x     x      x   \n",
       "weight_decay                 x        x         x       x    x     x      x   \n",
       "eps                                   x         x       x    x     x      x   \n",
       "capturable                   x        x                      x     x      x   \n",
       "betas                                                        x     x      x   \n",
       "fused                                                   x    x     x          \n",
       "alpha                        x                                                \n",
       "amsgrad                                                      x     x          \n",
       "decoupled_weight_decay                                                        \n",
       "momentum                                                                      \n",
       "beta2_decay                                     x                             \n",
       "centered                                                                      \n",
       "d                                               x                             \n",
       "dampening                                                                     \n",
       "etas                                                                          \n",
       "history_size                                                                  \n",
       "initial_accumulator_value                               x                     \n",
       "lambd                        x                                                \n",
       "line_search_fn                                                                \n",
       "lr_decay                                                x                     \n",
       "max_eval                                                                      \n",
       "max_iter                                                                      \n",
       "momentum_decay                                                                \n",
       "nesterov                                                                      \n",
       "rho                                   x                                       \n",
       "step_sizes                                                                    \n",
       "t0                           x                                                \n",
       "tolerance_change                                                              \n",
       "tolerance_grad                                                                \n",
       "\n",
       "                          LBFGS NAdam RAdam RMSprop Rprop SGD SparseAdam  \n",
       "lr                            x     x     x       x     x   x          x  \n",
       "maximize                            x     x       x     x   x          x  \n",
       "foreach                             x     x       x     x   x             \n",
       "differentiable                      x     x       x     x   x             \n",
       "weight_decay                        x     x       x         x             \n",
       "eps                                 x     x       x                    x  \n",
       "capturable                          x     x       x     x                 \n",
       "betas                               x     x                            x  \n",
       "fused                                                       x             \n",
       "alpha                                             x                       \n",
       "amsgrad                                                                   \n",
       "decoupled_weight_decay              x     x                               \n",
       "momentum                                          x         x             \n",
       "beta2_decay                                                               \n",
       "centered                                          x                       \n",
       "d                                                                         \n",
       "dampening                                                   x             \n",
       "etas                                                    x                 \n",
       "history_size                  x                                           \n",
       "initial_accumulator_value                                                 \n",
       "lambd                                                                     \n",
       "line_search_fn                x                                           \n",
       "lr_decay                                                                  \n",
       "max_eval                      x                                           \n",
       "max_iter                      x                                           \n",
       "momentum_decay                      x                                     \n",
       "nesterov                                                    x             \n",
       "rho                                                                       \n",
       "step_sizes                                              x                 \n",
       "t0                                                                        \n",
       "tolerance_change              x                                           \n",
       "tolerance_grad                x                                           "
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_comparison_data(q, 'torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "7496feba-6c94-46ec-8683-1f9ef319326c",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "from typing import Optional\n",
    "\n",
    "import pydantic as pyd\n",
    "\n",
    "OptBool = Optional[bool]\n",
    "# ------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "class BaseConfig(pyd.BaseModel):\n",
    "    name: str\n",
    "\n",
    "\n",
    "class TFBaseConfig(BaseConfig):\n",
    "    clipnorm: OptBool = None\n",
    "    clipvalue: OptBool = None\n",
    "    ema_momentum: float = 0.99\n",
    "    ema_overwrite_frequency: OptBool = None\n",
    "    global_clipnorm: OptBool = None\n",
    "    gradient_accumulation_steps: OptBool = None\n",
    "    learning_rate: float = 0.001\n",
    "    loss_scale_factor: OptBool = None\n",
    "    use_ema: bool = False\n",
    "    weight_decay: OptBool = None\n",
    "\n",
    "\n",
    "class TFEps(pyd.BaseModel):\n",
    "    epsilon: float = 1e-07\n",
    "\n",
    "\n",
    "class TFBeta(pyd.BaseModel):\n",
    "    beta_1: float = 0.9\n",
    "    beta_2: float = 0.99\n",
    "\n",
    "\n",
    "class TFAdafactorConfig(TFBaseConfig):\n",
    "    beta_2_decay: float = -0.8\n",
    "    clip_threshold: float = 1.0\n",
    "    epsilon_1: float = 1e-30\n",
    "    epsilon_2: float = 0.001\n",
    "    relative_step: bool = True\n",
    "\n",
    "\n",
    "class TFFtrlConfig(TFBaseConfig):\n",
    "    beta: float = 0.0\n",
    "    initial_accumulator_value: float = 0.1\n",
    "    l1_regularization_strength: float = 0.0\n",
    "    l2_regularization_strength: float = 0.0\n",
    "    l2_shrinkage_regularization_strength: float = 0.0\n",
    "    learning_rate_power: float = -0.5\n",
    "\n",
    "\n",
    "class TFLionConfig(TFBaseConfig, TFBeta):\n",
    "    pass\n",
    "\n",
    "\n",
    "class TFSGDConfig(TFBaseConfig):\n",
    "    momentum: float = 0.0\n",
    "    nesterov: bool = False\n",
    "\n",
    "\n",
    "class TFAdadeltaConfig(TFBaseConfig, TFEps):\n",
    "    rho: float = 0.95\n",
    "\n",
    "\n",
    "class TFAdagradConfig(TFBaseConfig, TFEps):\n",
    "    initial_accumulator_value: float = 0.1\n",
    "\n",
    "\n",
    "class TFAdamConfig(TFBaseConfig, TFBeta, TFEps):\n",
    "    amsgrad: bool = False\n",
    "\n",
    "\n",
    "class TFAdamWConfig(TFBaseConfig, TFBeta, TFEps):\n",
    "    amsgrad: bool = False\n",
    "\n",
    "\n",
    "class TFAdamaxConfig(TFBaseConfig, TFBeta, TFEps):\n",
    "    pass\n",
    "\n",
    "\n",
    "class TFLambConfig(TFBaseConfig, TFBeta, TFEps):\n",
    "    pass\n",
    "\n",
    "\n",
    "class TFNadamConfig(TFBaseConfig, TFBeta, TFEps):\n",
    "    pass\n",
    "\n",
    "\n",
    "class TFRMSpropConfig(TFBaseConfig, TFEps):\n",
    "    centered: bool = False\n",
    "    momentum: float = 0.0\n",
    "    rho: float = 0.9\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "20ca5363-c64e-466b-88d0-cf92b2a925c2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1769482/357340166.py:1: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.10/migration/\n",
      "  TFAdamWConfig(name='your-mom').dict()\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'epsilon': 1e-07,\n",
       " 'beta_1': 0.9,\n",
       " 'beta_2': 0.99,\n",
       " 'name': 'your-mom',\n",
       " 'clipnorm': None,\n",
       " 'clipvalue': None,\n",
       " 'ema_momentum': 0.99,\n",
       " 'ema_overwrite_frequency': None,\n",
       " 'global_clipnorm': None,\n",
       " 'gradient_accumulation_steps': None,\n",
       " 'learning_rate': 0.001,\n",
       " 'loss_scale_factor': None,\n",
       " 'use_ema': False,\n",
       " 'weight_decay': None,\n",
       " 'amsgrad': False}"
      ]
     },
     "execution_count": 165,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "TFAdamWConfig(name='your-mom').dict()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "462164c4-054a-47d6-aded-6c9d3dc6501c",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
