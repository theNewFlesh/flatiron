{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 350,
   "id": "4075517e-3967-403c-bff6-005582374c48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras  # noqa: F401\n",
    "from keras import optimizers as tfoptim\n",
    "from keras import losses as tfloss\n",
    "from keras import metrics as tfmetric\n",
    "\n",
    "import torch\n",
    "import torch.optim as torchoptim\n",
    "import torch.nn.modules.loss as torchloss\n",
    "import torchmetrics as torchmetric\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "\n",
    "import flatiron.core.tools as fict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "id": "db3144b2-94d8-4baf-9d91-1711572a1690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_classes(module):\n",
    "    members = inspect.getmembers(module)\n",
    "    members = list(filter(lambda x: inspect.isclass(x[1]), members))\n",
    "    members = list(filter(lambda x: not x[0].startswith('_'), members))\n",
    "    classes = dict(members)\n",
    "    return classes\n",
    "\n",
    "def create_signature(arg, annotation, default):\n",
    "    if annotation == 'UNTYPED':\n",
    "        annotation = 'Any'\n",
    "    if default == 'REQUIRED':\n",
    "        default = ''\n",
    "    else:\n",
    "        default = f' = {default}'\n",
    "    return f'{arg}: {annotation}{default}'\n",
    "\n",
    "def get_init_signature_data(class_, remove=['self']):\n",
    "    sig = inspect.getfullargspec(class_)\n",
    "    args = sig.args\n",
    "    for item in remove:\n",
    "        args.remove(item)\n",
    "\n",
    "    if sig.defaults is not None:\n",
    "        d = len(args) - len(sig.defaults)\n",
    "        req = args[:d]\n",
    "        opt = args[d:]\n",
    "        args = {k: 'REQUIRED' for k in req}\n",
    "        opt = dict(zip(opt, sig.defaults))\n",
    "        args.update(opt)\n",
    "    else:\n",
    "        args = {k: 'REQUIRED' for k in args}\n",
    "    \n",
    "    if isinstance(sig.kwonlydefaults, dict):\n",
    "        args.update(sig.kwonlydefaults)\n",
    "    \n",
    "    anno = sig.annotations\n",
    "    for key, val in args.items():\n",
    "        if key in anno:\n",
    "            args[key] = (val, anno[key].__name__)\n",
    "        else:\n",
    "            args[key] = (val, 'UNTYPED')\n",
    "            \n",
    "    data = []\n",
    "    for arg, (default, type_) in args.items():\n",
    "        data.append(dict(\n",
    "            arg=arg,\n",
    "            default=default,\n",
    "            type_=type_,\n",
    "            signature=create_signature(arg, type_, default),\n",
    "        ))\n",
    "    return data\n",
    "\n",
    "def get_module_class_data(module):\n",
    "    classes = get_classes(module)\n",
    "    data = []\n",
    "    for name, item in classes.items():\n",
    "        try:\n",
    "            datum = get_init_signature_data(item)\n",
    "        except:\n",
    "            continue\n",
    "        for row in datum:\n",
    "            row['class_'] = name\n",
    "        data.extend(datum)\n",
    "        \n",
    "    cols = ['class_', 'arg', 'type_', 'default', 'signature']\n",
    "    data = pd.DataFrame(data, columns=cols)\n",
    "    data['library'] = module.__name__.split('.')[0]\n",
    "    data['module'] = module.__name__\n",
    "    cols.insert(0, 'library')\n",
    "    cols.insert(1, 'module')\n",
    "    data = data[cols]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def _get_data(tf_module, torch_module):\n",
    "    tf_data = get_module_class_data(tf_module)\n",
    "    torch_data = get_module_class_data(torch_module)\n",
    "    data = pd.concat([tf_data, torch_data], axis=0)\n",
    "\n",
    "    mask = data.library == 'keras'\n",
    "    data.loc[mask, 'library'] = 'tf'\n",
    "    \n",
    "    mask = data.library == 'torchmetrics'\n",
    "    data.loc[mask, 'library'] = 'torch'\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_optimizer_data():\n",
    "    data = _get_data(tfoptim, torchoptim)\n",
    "\n",
    "    data['field'] = data['class_']\n",
    "    mask = data.field == 'Nadam'\n",
    "    data.loc[mask, 'field'] = 'NAdam'\n",
    "    \n",
    "    mask = data.class_.apply(lambda x: x not in ['Optimizer', 'LossScaleOptimizer'])\n",
    "    data = data[mask]\n",
    "    \n",
    "    mask = data.arg != 'params'\n",
    "    data = data[mask]\n",
    "\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_loss_data():\n",
    "    data = _get_data(tfoptim, torchoptim)    \n",
    "    mask = data.class_.apply(lambda x: x not in ['deprecated'])\n",
    "    data = data[mask]\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    return data\n",
    "\n",
    "def get_metric_data():\n",
    "    data = _get_data(tfmetric, torchmetric)    \n",
    "    mask = data.class_.apply(lambda x: x not in ['deprecated'])\n",
    "    data = data[mask]\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    return data\n",
    "\n",
    "def get_class_definitions(data, base_class='BaseConfig'):\n",
    "    data = data.copy()\n",
    "    data['config_name'] = data \\\n",
    "        .apply(lambda x: f'class {x.library.capitalize()}{x.class_}Config({base_class}):', axis=1) \\\n",
    "        .apply(lambda x: re.sub(' Tf', ' TF', x))\n",
    "    class_def = data \\\n",
    "        .groupby('config_name', as_index=False) \\\n",
    "        .signature.agg(lambda x: '    ' + '\\n    '.join(sorted(x)))\n",
    "    class_def = class_def \\\n",
    "        .apply(lambda x: f'{x.config_name}\\n{x.signature}', axis=1) \\\n",
    "        .apply(lambda x: re.sub(' +$', '', x))\n",
    "    return class_def.tolist()\n",
    "\n",
    "def get_comparison_data(data, mask=None):\n",
    "    data = data.copy()\n",
    "    if mask is not None:\n",
    "        mask = data.library == mask\n",
    "        data = data[mask]\n",
    "    data = data.groupby('arg', as_index=False)[['library', 'class_']].agg(lambda x: x.unique())\n",
    "    data['len_library'] = data.library.apply(len)\n",
    "    data['len_class'] = data.class_.apply(len)\n",
    "    data.sort_values(['len_class', 'len_library'], ascending=False, inplace=True)\n",
    "    return data\n",
    "\n",
    "def get_comparison_checkboxes(data, mask=None):\n",
    "    data = get_comparison_data(data, mask=mask)\n",
    "    output = data.class_.apply(lambda x: {k: k for k in x}).tolist()\n",
    "    index = data.arg.tolist()\n",
    "    output = pd.DataFrame(output, index=index).map(lambda x: '' if pd.isnull(x) else 'x')\n",
    "    return output\n",
    "\n",
    "def get_base_class_text(data, arg, class_, base_class, class_re):\n",
    "    mask = data.arg.apply(lambda x: x == arg)\n",
    "    temp = data[mask]\n",
    "    if len(temp) == 0:\n",
    "        raise ValueError(f'{arg} arg sux')\n",
    "    result = get_class_definitions(temp, base_class)[0]\n",
    "    result = re.sub(class_re, f'class {class_}', result)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_subclass_text(aux, library, class_, inherit, signature, descriptor):\n",
    "    caplib = library.capitalize()\n",
    "    inherit = ', '.join(sorted(filter(lambda x: x != '', inherit)))\n",
    "    output = f'class {caplib}{descriptor}{class_}Config({caplib}BaseConfig, {inherit}):\\n    '\n",
    "    output = re.sub(r', \\)', ')', output)\n",
    "    regex = '|'.join(aux.keys())\n",
    "    regex = f'({regex}):'\n",
    "    signature = list(filter(lambda x: not re.search(regex, x), signature))\n",
    "    if signature == []:\n",
    "        output += 'pass'\n",
    "    else:\n",
    "        output += '\\n    '.join(sorted(signature))\n",
    "    output = re.sub(' +$', '', output)\n",
    "    return output\n",
    "\n",
    "\n",
    "def print_config_definitions(data, aux, library, descriptor):\n",
    "    caplib = library.capitalize()\n",
    "    class_re = f'class {caplib}[a-zA-Z]*Config'\n",
    "\n",
    "    mask = data.library == library\n",
    "    data = data[mask]\n",
    "\n",
    "    # base class\n",
    "    base = get_class_definitions(data)[0].split('\\n')[0]\n",
    "    base = re.sub(class_re, f'class {caplib}BaseConfig', base)\n",
    "    base += '\\n    name: str'\n",
    "    print(f'# {library.upper()}' + '-' * 70)\n",
    "    print(base, '\\n\\n')\n",
    "\n",
    "    # helper classes\n",
    "    print('# HELPERS' + '-' * 70)\n",
    "    data['inherit'] = ''\n",
    "    for arg, cls_ in aux.items():\n",
    "        text = get_base_class_text(data, arg, cls_, 'pyd.BaseModel', class_re)\n",
    "        print(text, '\\n\\n')\n",
    "        mask = data.arg == arg\n",
    "        data.loc[mask, 'inherit'] = cls_\n",
    "\n",
    "    # subclasses\n",
    "    print('# ' + '-' * 78)\n",
    "    class_def = data \\\n",
    "        .sort_values('class_') \\\n",
    "        .groupby('class_', as_index=False)[['inherit', 'signature']] \\\n",
    "        .agg(lambda x: x) \\\n",
    "        .apply(lambda x: get_subclass_text(\n",
    "            aux, library, x.class_, x.inherit, x.signature, descriptor), axis=1\n",
    "        ).tolist()\n",
    "    for item in class_def:\n",
    "        print(item, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 398,
   "id": "fc4d25f8-76e7-4713-89b3-6d21c667e0c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_tf_optimizer_config_definitions():\n",
    "    # TF\n",
    "    d = get_optimizer_data()\n",
    "    mask = d.library == 'tf'\n",
    "    d = d[mask]\n",
    "\n",
    "    # TFBaseConfig\n",
    "    tf_base_args = [\n",
    "        'clipnorm',\n",
    "        'clipvalue',\n",
    "        'ema_momentum',\n",
    "        'ema_overwrite_frequency',\n",
    "        'global_clipnorm',\n",
    "        'gradient_accumulation_steps',\n",
    "        'learning_rate',\n",
    "        'loss_scale_factor',\n",
    "        'name',\n",
    "        'use_ema',\n",
    "        'weight_decay',\n",
    "    ]\n",
    "    mask = d.arg.apply(lambda x: x in tf_base_args)\n",
    "    d0 = d[mask]\n",
    "    tf_base = get_class_definitions(d0)[0]\n",
    "    tf_base = re.sub('TFAdadeltaConfig', 'TFBaseConfig', tf_base)\n",
    "    print(tf_base, '\\n\\n')\n",
    "\n",
    "    # TFEpsilonBaseConfig\n",
    "    tf_eps_args = ['epsilon']\n",
    "    mask = d.arg.apply(lambda x: x in tf_eps_args)\n",
    "    d1 = d[mask]\n",
    "    tf_eps = get_class_definitions(d1, 'TFBaseConfig')[0]\n",
    "    tf_eps = re.sub('class TF[a-zA-Z]*Config', 'class TFEpsilonBaseConfig', tf_eps)\n",
    "    print(tf_eps, '\\n\\n')\n",
    "    \n",
    "    # TFEpsilonBaseConfig\n",
    "    tf_eps_args = ['epsilon']\n",
    "    mask = d.arg.apply(lambda x: x in tf_eps_args)\n",
    "    d1 = d[mask]\n",
    "    tf_eps = get_class_definitions(d1, 'TFBaseConfig')[0]\n",
    "    tf_eps = re.sub('class TF[a-zA-Z]*Config', 'class TFEpsilonBaseConfig', tf_eps)\n",
    "    print(tf_eps, '\\n\\n')\n",
    "\n",
    "    # TFBaseConfig subclasses\n",
    "    eps_classes = d1.class_.unique().tolist()\n",
    "    mask = d.class_.apply(lambda x: x in eps_classes)\n",
    "    d2 = d[~mask]\n",
    "    mask = d2.arg.apply(lambda x: x in tf_base_args)\n",
    "    d2 = d2[~mask]\n",
    "    tf_subclass = get_class_definitions(d2, 'TFBaseConfig')\n",
    "    for item in tf_subclass:\n",
    "        print(item, '\\n\\n')\n",
    "\n",
    "    # TFEpsilonBaseConfig subclasses\n",
    "    eps_classes = d1.class_.unique().tolist()\n",
    "    mask = d.class_.apply(lambda x: x in eps_classes)\n",
    "    d2 = d[mask]\n",
    "    mask = d2.arg.apply(lambda x: x in tf_base_args or x in tf_eps_args)\n",
    "    d2 = d2[~mask]\n",
    "    tf_eps_subclass = get_class_definitions(d2, 'TFEpsilonBaseConfig')\n",
    "    for item in tf_eps_subclass:\n",
    "        print(item, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 399,
   "id": "4c622127-b00a-4a63-ae66-074c61349810",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_torch_loss():\n",
    "    data = get_loss_data()\n",
    "    aux = dict(\n",
    "        reduction='TReduct',\n",
    "        reduce='TRed',\n",
    "        size_average='TSize',\n",
    "        margin='TMarg',\n",
    "        weight='TWeight',\n",
    "        eps='TEps',\n",
    "    )\n",
    "    print_config_definitions(data, aux, 'torch', 'Loss')\n",
    "\n",
    "def print_torch_optimizer():\n",
    "    data = get_optimizer_data()\n",
    "    aux = dict(\n",
    "        lr='TLR',\n",
    "        maximize='TMax',\n",
    "        foreach='TFor',\n",
    "        differentiable='TDiff',\n",
    "        eps='TEps',\n",
    "        capturable='TCap',\n",
    "        weight_decay='TDecay',\n",
    "    )\n",
    "    print_config_definitions(data, aux, 'torch', 'Opt')\n",
    "    \n",
    "def print_torch_metric():\n",
    "    data = get_metric_data()\n",
    "    aux = dict(\n",
    "        ignore_index='TInd',\n",
    "        nan_strategy='TNan',\n",
    "        empty_target_action='TAct',\n",
    "        num_outputs='TOut',\n",
    "        reduction='TReduct',\n",
    "        top_k='TTopK',\n",
    "        num_classes='TCls',\n",
    "    )\n",
    "    print_config_definitions(data, aux, 'torch', 'Metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "6c8455d9-718a-4d86-aced-2af4e9192e01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# TORCH----------------------------------------------------------------------\n",
      "class TorchBaseConfig(BaseConfig):\n",
      "    name: str \n",
      "\n",
      "\n",
      "# HELPERS----------------------------------------------------------------------\n",
      "class TLR(pyd.BaseModel):\n",
      "    lr: Union = 0.01 \n",
      "\n",
      "\n",
      "class TMax(pyd.BaseModel):\n",
      "    maximize: bool = False \n",
      "\n",
      "\n",
      "class TFor(pyd.BaseModel):\n",
      "    foreach: Optional = None \n",
      "\n",
      "\n",
      "class TDiff(pyd.BaseModel):\n",
      "    differentiable: bool = False \n",
      "\n",
      "\n",
      "class TEps(pyd.BaseModel):\n",
      "    eps: float = 1e-06 \n",
      "\n",
      "\n",
      "class TCap(pyd.BaseModel):\n",
      "    capturable: bool = False \n",
      "\n",
      "\n",
      "class TDecay(pyd.BaseModel):\n",
      "    weight_decay: float = 0 \n",
      "\n",
      "\n",
      "# ------------------------------------------------------------------------------\n",
      "class TorchOptASGDConfig(TorchBaseConfig, TCap, TDecay, TDiff, TFor, TLR, TMax):\n",
      "    alpha: float = 0.75\n",
      "    lambd: float = 0.0001\n",
      "    t0: float = 1000000.0 \n",
      "\n",
      "\n",
      "class TorchOptAdadeltaConfig(TorchBaseConfig, TCap, TDecay, TDiff, TEps, TFor, TLR, TMax):\n",
      "    rho: float = 0.9 \n",
      "\n",
      "\n",
      "class TorchOptAdafactorConfig(TorchBaseConfig, TDecay, TEps, TFor, TLR, TMax):\n",
      "    beta2_decay: float = -0.8\n",
      "    d: float = 1.0 \n",
      "\n",
      "\n",
      "class TorchOptAdagradConfig(TorchBaseConfig, TDecay, TDiff, TEps, TFor, TLR, TMax):\n",
      "    fused: Optional = None\n",
      "    initial_accumulator_value: float = 0\n",
      "    lr_decay: float = 0 \n",
      "\n",
      "\n",
      "class TorchOptAdamConfig(TorchBaseConfig, TCap, TDecay, TDiff, TEps, TFor, TLR, TMax):\n",
      "    amsgrad: bool = False\n",
      "    betas: Tuple = (0.9, 0.999)\n",
      "    fused: Optional = None \n",
      "\n",
      "\n",
      "class TorchOptAdamWConfig(TorchBaseConfig, TCap, TDecay, TDiff, TEps, TFor, TLR, TMax):\n",
      "    amsgrad: bool = False\n",
      "    betas: Tuple = (0.9, 0.999)\n",
      "    fused: Optional = None \n",
      "\n",
      "\n",
      "class TorchOptAdamaxConfig(TorchBaseConfig, TCap, TDecay, TDiff, TEps, TFor, TLR, TMax):\n",
      "    betas: Tuple = (0.9, 0.999) \n",
      "\n",
      "\n",
      "class TorchOptLBFGSConfig(TorchBaseConfig, TLR):\n",
      "    history_size: int = 100\n",
      "    line_search_fn: Optional = None\n",
      "    max_eval: Optional = None\n",
      "    max_iter: int = 20\n",
      "    tolerance_change: float = 1e-09\n",
      "    tolerance_grad: float = 1e-07 \n",
      "\n",
      "\n",
      "class TorchOptNAdamConfig(TorchBaseConfig, TCap, TDecay, TDiff, TEps, TFor, TLR, TMax):\n",
      "    betas: Tuple = (0.9, 0.999)\n",
      "    momentum_decay: float = 0.004 \n",
      "\n",
      "\n",
      "class TorchOptRAdamConfig(TorchBaseConfig, TCap, TDecay, TDiff, TEps, TFor, TLR, TMax):\n",
      "    betas: Tuple = (0.9, 0.999) \n",
      "\n",
      "\n",
      "class TorchOptRMSpropConfig(TorchBaseConfig, TCap, TDecay, TDiff, TEps, TFor, TLR, TMax):\n",
      "    alpha: float = 0.99\n",
      "    centered: bool = False\n",
      "    momentum: float = 0 \n",
      "\n",
      "\n",
      "class TorchOptRpropConfig(TorchBaseConfig, TCap, TDiff, TFor, TLR, TMax):\n",
      "    etas: Tuple = (0.5, 1.2)\n",
      "    step_sizes: Tuple = (1e-06, 50) \n",
      "\n",
      "\n",
      "class TorchOptSGDConfig(TorchBaseConfig, TDecay, TDiff, TFor, TLR, TMax):\n",
      "    dampening: float = 0\n",
      "    fused: Optional = None\n",
      "    momentum: float = 0\n",
      "    nesterov: bool = False \n",
      "\n",
      "\n",
      "class TorchOptSparseAdamConfig(TorchBaseConfig, TEps, TLR, TMax):\n",
      "    betas: Tuple = (0.9, 0.999) \n",
      "\n",
      "\n",
      "# TORCH----------------------------------------------------------------------\n",
      "class TorchBaseConfig(BaseConfig):\n",
      "    name: str \n",
      "\n",
      "\n",
      "# HELPERS----------------------------------------------------------------------\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1769482/2008018604.py:192: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['inherit'] = ''\n",
      "/tmp/ipykernel_1769482/2008018604.py:192: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['inherit'] = ''\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "reduction arg sux",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[401], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m print_torch_optimizer()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mprint_torch_loss\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      3\u001b[0m print_torch_metric()\n",
      "Cell \u001b[0;32mIn[399], line 11\u001b[0m, in \u001b[0;36mprint_torch_loss\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m data \u001b[38;5;241m=\u001b[39m get_loss_data()\n\u001b[1;32m      3\u001b[0m aux \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m      4\u001b[0m     reduction\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTReduct\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m      5\u001b[0m     reduce\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTRed\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m      9\u001b[0m     eps\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTEps\u001b[39m\u001b[38;5;124m'\u001b[39m,\n\u001b[1;32m     10\u001b[0m )\n\u001b[0;32m---> 11\u001b[0m \u001b[43mprint_config_definitions\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43maux\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtorch\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mLoss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[0;32mIn[397], line 194\u001b[0m, in \u001b[0;36mprint_config_definitions\u001b[0;34m(data, aux, library, descriptor)\u001b[0m\n\u001b[1;32m    192\u001b[0m data[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124minherit\u001b[39m\u001b[38;5;124m'\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    193\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m arg, cls_ \u001b[38;5;129;01min\u001b[39;00m aux\u001b[38;5;241m.\u001b[39mitems():\n\u001b[0;32m--> 194\u001b[0m     text \u001b[38;5;241m=\u001b[39m \u001b[43mget_base_class_text\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43marg\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcls_\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mpyd.BaseModel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclass_re\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    195\u001b[0m     \u001b[38;5;28mprint\u001b[39m(text, \u001b[38;5;124m'\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    196\u001b[0m     mask \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39marg \u001b[38;5;241m==\u001b[39m arg\n",
      "Cell \u001b[0;32mIn[397], line 154\u001b[0m, in \u001b[0;36mget_base_class_text\u001b[0;34m(data, arg, class_, base_class, class_re)\u001b[0m\n\u001b[1;32m    152\u001b[0m temp \u001b[38;5;241m=\u001b[39m data[mask]\n\u001b[1;32m    153\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(temp) \u001b[38;5;241m==\u001b[39m \u001b[38;5;241m0\u001b[39m:\n\u001b[0;32m--> 154\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00marg\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m arg sux\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    155\u001b[0m result \u001b[38;5;241m=\u001b[39m get_class_definitions(temp, base_class)[\u001b[38;5;241m0\u001b[39m]\n\u001b[1;32m    156\u001b[0m result \u001b[38;5;241m=\u001b[39m re\u001b[38;5;241m.\u001b[39msub(class_re, \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mclass \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mclass_\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m, result)\n",
      "\u001b[0;31mValueError\u001b[0m: reduction arg sux"
     ]
    }
   ],
   "source": [
    "print_torch_optimizer()\n",
    "print_torch_loss()\n",
    "print_torch_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "id": "c904975d-b584-40f2-b6c8-49668660cb01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "ignore_index                    12\n",
       "nan_strategy                    11\n",
       "empty_target_action             10\n",
       "num_outputs                     10\n",
       "reduction                       10\n",
       "top_k                            7\n",
       "num_classes                      5\n",
       "nan_replace_value                4\n",
       "adaptive_k                       3\n",
       "base_metric                      3\n",
       "data_range                       3\n",
       "kernel_size                      3\n",
       "lowercase                        3\n",
       "postfix                          3\n",
       "prefix                           3\n",
       "return_sentence_level_score      3\n",
       "sigma                            3\n",
       "zero_mean                        3\n",
       "allow_unknown_preds_category     2\n",
       "bias_correction                  2\n",
       "gaussian_kernel                  2\n",
       "k1                               2\n",
       "k2                               2\n",
       "max_k                            2\n",
       "metric                           2\n",
       "mode                             2\n",
       "multioutput                      2\n",
       "n_gram                           2\n",
       "normalize                        2\n",
       "p                                2\n",
       "smooth                           2\n",
       "squared                          2\n",
       "stuffs                           2\n",
       "things                           2\n",
       "threshold                        2\n",
       "weights                          2\n",
       "window                           2\n",
       "window_size                      2\n",
       "adjusted                         1\n",
       "alpha                            1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 388,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_metric_data()\n",
    "get_comparison_checkboxes(data, 'torch').T.map(lambda x: 1 if x == 'x' else 0).sum().head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc3e992-1eaa-4e63-913f-04cd260285b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
