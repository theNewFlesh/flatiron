{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "4075517e-3967-403c-bff6-005582374c48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras  # noqa: F401\n",
    "from keras import optimizers as tfoptim\n",
    "from keras import losses as tfloss\n",
    "\n",
    "import torch\n",
    "import torch.optim as torchoptim\n",
    "import torch.nn.modules.loss as torchloss\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "\n",
    "import flatiron.core.tools as fict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 346,
   "id": "db3144b2-94d8-4baf-9d91-1711572a1690",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def get_classes(module):\n",
    "    members = inspect.getmembers(module)\n",
    "    members = list(filter(lambda x: inspect.isclass(x[1]), members))\n",
    "    members = list(filter(lambda x: not x[0].startswith('_'), members))\n",
    "    classes = dict(members)\n",
    "    return classes\n",
    "\n",
    "def create_signature(arg, annotation, default):\n",
    "    if annotation == 'UNTYPED':\n",
    "        annotation = 'Any'\n",
    "    if default == 'REQUIRED':\n",
    "        default = ''\n",
    "    else:\n",
    "        default = f' = {default}'\n",
    "    return f'{arg}: {annotation}{default}'\n",
    "\n",
    "def get_init_signature_data(class_, remove=['self']):\n",
    "    sig = inspect.getfullargspec(class_)\n",
    "    args = sig.args\n",
    "    for item in remove:\n",
    "        args.remove(item)\n",
    "\n",
    "    if sig.defaults is not None:\n",
    "        d = len(args) - len(sig.defaults)\n",
    "        req = args[:d]\n",
    "        opt = args[d:]\n",
    "        args = {k: 'REQUIRED' for k in req}\n",
    "        opt = dict(zip(opt, sig.defaults))\n",
    "        args.update(opt)\n",
    "    else:\n",
    "        args = {k: 'REQUIRED' for k in args}\n",
    "    \n",
    "    if isinstance(sig.kwonlydefaults, dict):\n",
    "        args.update(sig.kwonlydefaults)\n",
    "    \n",
    "    anno = sig.annotations\n",
    "    for key, val in args.items():\n",
    "        if key in anno:\n",
    "            args[key] = (val, anno[key].__name__)\n",
    "        else:\n",
    "            args[key] = (val, 'UNTYPED')\n",
    "            \n",
    "    data = []\n",
    "    for arg, (default, type_) in args.items():\n",
    "        data.append(dict(\n",
    "            arg=arg,\n",
    "            default=default,\n",
    "            type_=type_,\n",
    "            signature=create_signature(arg, type_, default),\n",
    "        ))\n",
    "    return data\n",
    "\n",
    "def get_module_class_data(module):\n",
    "    classes = get_classes(module)\n",
    "    data = []\n",
    "    for name, item in classes.items():\n",
    "        try:\n",
    "            datum = get_init_signature_data(item)\n",
    "        except:\n",
    "            continue\n",
    "        for row in datum:\n",
    "            row['class_'] = name\n",
    "        data.extend(datum)\n",
    "        \n",
    "    cols = ['class_', 'arg', 'type_', 'default', 'signature']\n",
    "    data = pd.DataFrame(data, columns=cols)\n",
    "    data['library'] = module.__name__.split('.')[0]\n",
    "    data['module'] = module.__name__\n",
    "    cols.insert(0, 'library')\n",
    "    cols.insert(1, 'module')\n",
    "    data = data[cols]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def get_optimizer_data():\n",
    "    tf_optim_data = get_module_class_data(tfoptim)\n",
    "    torch_optim_data = get_module_class_data(torchoptim)\n",
    "    data = pd.concat([tf_optim_data, torch_optim_data], axis=0)\n",
    "    \n",
    "    mask = data.library == 'keras'\n",
    "    data.loc[mask, 'library'] = 'tf'\n",
    "    \n",
    "    data['field'] = data['class_']\n",
    "    mask = data.field == 'Nadam'\n",
    "    data.loc[mask, 'field'] = 'NAdam'\n",
    "    \n",
    "    mask = data.class_.apply(lambda x: x not in ['Optimizer', 'LossScaleOptimizer'])\n",
    "    data = data[mask]\n",
    "    \n",
    "    mask = data.arg != 'params'\n",
    "    data = data[mask]\n",
    "\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_loss_data():\n",
    "    tf_loss_data = get_module_class_data(tfloss)\n",
    "    torch_loss_data = get_module_class_data(torchloss)\n",
    "    data = pd.concat([tf_loss_data, torch_loss_data], axis=0)\n",
    "    \n",
    "    mask = data.library == 'keras'\n",
    "    data.loc[mask, 'library'] = 'tf'\n",
    "    \n",
    "    mask = data.class_.apply(lambda x: x not in ['deprecated'])\n",
    "    data = data[mask]\n",
    "\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_class_definitions(data, base_class='BaseConfig'):\n",
    "    data = data.copy()\n",
    "    data['config_name'] = data \\\n",
    "        .apply(lambda x: f'class {x.library.capitalize()}{x.class_}Config({base_class}):', axis=1) \\\n",
    "        .apply(lambda x: re.sub(' Tf', ' TF', x))\n",
    "    class_def = data \\\n",
    "        .groupby('config_name', as_index=False) \\\n",
    "        .signature.agg(lambda x: '    ' + '\\n    '.join(sorted(x)))\n",
    "    class_def = class_def \\\n",
    "        .apply(lambda x: f'{x.config_name}\\n{x.signature}', axis=1) \\\n",
    "        .apply(lambda x: re.sub(' +$', '', x))\n",
    "    return class_def.tolist()\n",
    "\n",
    "def get_comparison_data(data, mask=None):\n",
    "    data = data.copy()\n",
    "    if mask is not None:\n",
    "        mask = data.library == mask\n",
    "        data = data[mask]\n",
    "    data = data.groupby('arg', as_index=False)[['library', 'class_']].agg(lambda x: x.unique())\n",
    "    data['len_library'] = data.library.apply(len)\n",
    "    data['len_class'] = data.class_.apply(len)\n",
    "    data.sort_values(['len_class', 'len_library'], ascending=False, inplace=True)\n",
    "    return data\n",
    "\n",
    "def get_comparison_checkboxes(data, mask=None):\n",
    "    data = get_comparison_data(data, mask=mask)\n",
    "    output = data.class_.apply(lambda x: {k: k for k in x}).tolist()\n",
    "    index = data.arg.tolist()\n",
    "    output = pd.DataFrame(output, index=index).map(lambda x: '' if pd.isnull(x) else 'x')\n",
    "    return output\n",
    "\n",
    "def get_base_class_text(data, arg, class_, base_class, class_re):\n",
    "    mask = data.arg.apply(lambda x: x == arg)\n",
    "    temp = data[mask]\n",
    "    if len(temp) == 0:\n",
    "        raise ValueError(f'{arg} arg sux')\n",
    "    result = get_class_definitions(temp, base_class)[0]\n",
    "    result = re.sub(class_re, f'class {class_}', result)\n",
    "    return result\n",
    "\n",
    "\n",
    "def get_subclass_text(aux, library, class_, inherit, signature):\n",
    "    caplib = library.capitalize()\n",
    "    inherit = ', '.join(sorted(filter(lambda x: x != '', inherit)))\n",
    "    output = f'class {caplib}{class_}Config({caplib}BaseConfig, {inherit}):\\n    '\n",
    "    output = re.sub(r', \\)', ')', output)\n",
    "    regex = '|'.join(aux.keys())\n",
    "    regex = f'({regex}):'\n",
    "    signature = list(filter(lambda x: not re.search(regex, x), signature))\n",
    "    if signature == []:\n",
    "        output += 'pass'\n",
    "    else:\n",
    "        output += '\\n    '.join(sorted(signature))\n",
    "    output = re.sub(' +$', '', output)\n",
    "    return output\n",
    "\n",
    "\n",
    "def print_config_definitions(data, aux, library):\n",
    "    caplib = library.capitalize()\n",
    "    class_re = f'class {caplib}[a-zA-Z]*Config'\n",
    "\n",
    "    mask = data.library == library\n",
    "    data = data[mask]\n",
    "\n",
    "    # base class\n",
    "    base = get_class_definitions(data)[0].split('\\n')[0]\n",
    "    base = re.sub(class_re, f'class {caplib}BaseConfig', base)\n",
    "    base += '\\n    name: str'\n",
    "    print(f'# {library.upper()}' + '-' * 70)\n",
    "    print(base, '\\n\\n')\n",
    "\n",
    "    # helper classes\n",
    "    print('# HELPERS' + '-' * 70)\n",
    "    data['inherit'] = ''\n",
    "    for arg, cls_ in aux.items():\n",
    "        text = get_base_class_text(data, arg, cls_, 'pyd.BaseModel', class_re)\n",
    "        print(text, '\\n\\n')\n",
    "        mask = data.arg == arg\n",
    "        data.loc[mask, 'inherit'] = cls_\n",
    "\n",
    "    # subclasses\n",
    "    print('# ' + '-' * 78)\n",
    "    class_def = data \\\n",
    "        .sort_values('class_') \\\n",
    "        .groupby('class_', as_index=False)[['inherit', 'signature']] \\\n",
    "        .agg(lambda x: x) \\\n",
    "        .apply(lambda x: get_subclass_text(\n",
    "            aux, library, x.class_, x.inherit, x.signature), axis=1\n",
    "        ).tolist()\n",
    "    for item in class_def:\n",
    "        print(item, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "id": "fc4d25f8-76e7-4713-89b3-6d21c667e0c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_tf_optimizer_config_definitions():\n",
    "    # TF\n",
    "    d = get_optimizer_data()\n",
    "    mask = d.library == 'tf'\n",
    "    d = d[mask]\n",
    "\n",
    "    # TFBaseConfig\n",
    "    tf_base_args = [\n",
    "        'clipnorm',\n",
    "        'clipvalue',\n",
    "        'ema_momentum',\n",
    "        'ema_overwrite_frequency',\n",
    "        'global_clipnorm',\n",
    "        'gradient_accumulation_steps',\n",
    "        'learning_rate',\n",
    "        'loss_scale_factor',\n",
    "        'name',\n",
    "        'use_ema',\n",
    "        'weight_decay',\n",
    "    ]\n",
    "    mask = d.arg.apply(lambda x: x in tf_base_args)\n",
    "    d0 = d[mask]\n",
    "    tf_base = get_class_definitions(d0)[0]\n",
    "    tf_base = re.sub('TFAdadeltaConfig', 'TFBaseConfig', tf_base)\n",
    "    print(tf_base, '\\n\\n')\n",
    "\n",
    "    # TFEpsilonBaseConfig\n",
    "    tf_eps_args = ['epsilon']\n",
    "    mask = d.arg.apply(lambda x: x in tf_eps_args)\n",
    "    d1 = d[mask]\n",
    "    tf_eps = get_class_definitions(d1, 'TFBaseConfig')[0]\n",
    "    tf_eps = re.sub('class TF[a-zA-Z]*Config', 'class TFEpsilonBaseConfig', tf_eps)\n",
    "    print(tf_eps, '\\n\\n')\n",
    "    \n",
    "    # TFEpsilonBaseConfig\n",
    "    tf_eps_args = ['epsilon']\n",
    "    mask = d.arg.apply(lambda x: x in tf_eps_args)\n",
    "    d1 = d[mask]\n",
    "    tf_eps = get_class_definitions(d1, 'TFBaseConfig')[0]\n",
    "    tf_eps = re.sub('class TF[a-zA-Z]*Config', 'class TFEpsilonBaseConfig', tf_eps)\n",
    "    print(tf_eps, '\\n\\n')\n",
    "\n",
    "    # TFBaseConfig subclasses\n",
    "    eps_classes = d1.class_.unique().tolist()\n",
    "    mask = d.class_.apply(lambda x: x in eps_classes)\n",
    "    d2 = d[~mask]\n",
    "    mask = d2.arg.apply(lambda x: x in tf_base_args)\n",
    "    d2 = d2[~mask]\n",
    "    tf_subclass = get_class_definitions(d2, 'TFBaseConfig')\n",
    "    for item in tf_subclass:\n",
    "        print(item, '\\n\\n')\n",
    "\n",
    "    # TFEpsilonBaseConfig subclasses\n",
    "    eps_classes = d1.class_.unique().tolist()\n",
    "    mask = d.class_.apply(lambda x: x in eps_classes)\n",
    "    d2 = d[mask]\n",
    "    mask = d2.arg.apply(lambda x: x in tf_base_args or x in tf_eps_args)\n",
    "    d2 = d2[~mask]\n",
    "    tf_eps_subclass = get_class_definitions(d2, 'TFEpsilonBaseConfig')\n",
    "    for item in tf_eps_subclass:\n",
    "        print(item, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "id": "4c622127-b00a-4a63-ae66-074c61349810",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_torch_loss():\n",
    "    data = get_loss_data()\n",
    "    aux = dict(\n",
    "        reduction='TReduct',\n",
    "        reduce='TRed',\n",
    "        size_average='TSize',\n",
    "        margin='TMarg',\n",
    "        weight='TWeight',\n",
    "        eps='TEps',\n",
    "    )\n",
    "    print_config_definitions(data, aux, 'torch')\n",
    "\n",
    "def print_torch_optimizer():\n",
    "    data = get_optimizer_data()\n",
    "    aux = dict(\n",
    "        lr='TLR',\n",
    "        maximize='TMax',\n",
    "        foreach='TFor',\n",
    "        differentiable='TDiff',\n",
    "        eps='TEps',\n",
    "        capturable='TCap',\n",
    "        weight_decay='TDecay',\n",
    "    )\n",
    "    print_config_definitions(data, aux, 'torch')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "id": "6c8455d9-718a-4d86-aced-2af4e9192e01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# TORCH----------------------------------------------------------------------\n",
      "class TorchBaseConfig(BaseConfig):\n",
      "    name: str \n",
      "\n",
      "\n",
      "# HELPERS----------------------------------------------------------------------\n",
      "class TLR(pyd.BaseModel):\n",
      "    lr: Union = 0.01 \n",
      "\n",
      "\n",
      "class TMax(pyd.BaseModel):\n",
      "    maximize: bool = False \n",
      "\n",
      "\n",
      "class TFor(pyd.BaseModel):\n",
      "    foreach: Optional = None \n",
      "\n",
      "\n",
      "class TDiff(pyd.BaseModel):\n",
      "    differentiable: bool = False \n",
      "\n",
      "\n",
      "class TEps(pyd.BaseModel):\n",
      "    eps: float = 1e-06 \n",
      "\n",
      "\n",
      "class TCap(pyd.BaseModel):\n",
      "    capturable: bool = False \n",
      "\n",
      "\n",
      "class TDecay(pyd.BaseModel):\n",
      "    weight_decay: float = 0 \n",
      "\n",
      "\n",
      "# ------------------------------------------------------------------------------\n",
      "class TorchASGDConfig(TorchBaseConfig, TCap, TDecay, TDiff, TFor, TLR, TMax):\n",
      "    alpha: float = 0.75\n",
      "    lambd: float = 0.0001\n",
      "    t0: float = 1000000.0 \n",
      "\n",
      "\n",
      "class TorchAdadeltaConfig(TorchBaseConfig, TCap, TDecay, TDiff, TEps, TFor, TLR, TMax):\n",
      "    rho: float = 0.9 \n",
      "\n",
      "\n",
      "class TorchAdafactorConfig(TorchBaseConfig, TDecay, TEps, TFor, TLR, TMax):\n",
      "    beta2_decay: float = -0.8\n",
      "    d: float = 1.0 \n",
      "\n",
      "\n",
      "class TorchAdagradConfig(TorchBaseConfig, TDecay, TDiff, TEps, TFor, TLR, TMax):\n",
      "    fused: Optional = None\n",
      "    initial_accumulator_value: float = 0\n",
      "    lr_decay: float = 0 \n",
      "\n",
      "\n",
      "class TorchAdamConfig(TorchBaseConfig, TCap, TDecay, TDiff, TEps, TFor, TLR, TMax):\n",
      "    amsgrad: bool = False\n",
      "    betas: Tuple = (0.9, 0.999)\n",
      "    fused: Optional = None \n",
      "\n",
      "\n",
      "class TorchAdamWConfig(TorchBaseConfig, TCap, TDecay, TDiff, TEps, TFor, TLR, TMax):\n",
      "    amsgrad: bool = False\n",
      "    betas: Tuple = (0.9, 0.999)\n",
      "    fused: Optional = None \n",
      "\n",
      "\n",
      "class TorchAdamaxConfig(TorchBaseConfig, TCap, TDecay, TDiff, TEps, TFor, TLR, TMax):\n",
      "    betas: Tuple = (0.9, 0.999) \n",
      "\n",
      "\n",
      "class TorchLBFGSConfig(TorchBaseConfig, TLR):\n",
      "    history_size: int = 100\n",
      "    line_search_fn: Optional = None\n",
      "    max_eval: Optional = None\n",
      "    max_iter: int = 20\n",
      "    tolerance_change: float = 1e-09\n",
      "    tolerance_grad: float = 1e-07 \n",
      "\n",
      "\n",
      "class TorchNAdamConfig(TorchBaseConfig, TCap, TDecay, TDiff, TEps, TFor, TLR, TMax):\n",
      "    betas: Tuple = (0.9, 0.999)\n",
      "    momentum_decay: float = 0.004 \n",
      "\n",
      "\n",
      "class TorchRAdamConfig(TorchBaseConfig, TCap, TDecay, TDiff, TEps, TFor, TLR, TMax):\n",
      "    betas: Tuple = (0.9, 0.999) \n",
      "\n",
      "\n",
      "class TorchRMSpropConfig(TorchBaseConfig, TCap, TDecay, TDiff, TEps, TFor, TLR, TMax):\n",
      "    alpha: float = 0.99\n",
      "    centered: bool = False\n",
      "    momentum: float = 0 \n",
      "\n",
      "\n",
      "class TorchRpropConfig(TorchBaseConfig, TCap, TDiff, TFor, TLR, TMax):\n",
      "    etas: Tuple = (0.5, 1.2)\n",
      "    step_sizes: Tuple = (1e-06, 50) \n",
      "\n",
      "\n",
      "class TorchSGDConfig(TorchBaseConfig, TDecay, TDiff, TFor, TLR, TMax):\n",
      "    dampening: float = 0\n",
      "    fused: Optional = None\n",
      "    momentum: float = 0\n",
      "    nesterov: bool = False \n",
      "\n",
      "\n",
      "class TorchSparseAdamConfig(TorchBaseConfig, TEps, TLR, TMax):\n",
      "    betas: Tuple = (0.9, 0.999) \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1769482/1534631603.py:57: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['inherit'] = ''\n"
     ]
    }
   ],
   "source": [
    "print_torch_optimizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "id": "c904975d-b584-40f2-b6c8-49668660cb01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>reduction</th>\n",
       "      <th>reduce</th>\n",
       "      <th>size_average</th>\n",
       "      <th>margin</th>\n",
       "      <th>weight</th>\n",
       "      <th>eps</th>\n",
       "      <th>p</th>\n",
       "      <th>full</th>\n",
       "      <th>ignore_index</th>\n",
       "      <th>swap</th>\n",
       "      <th>beta</th>\n",
       "      <th>blank</th>\n",
       "      <th>delta</th>\n",
       "      <th>distance_function</th>\n",
       "      <th>keepdim</th>\n",
       "      <th>label_smoothing</th>\n",
       "      <th>log_input</th>\n",
       "      <th>log_target</th>\n",
       "      <th>pos_weight</th>\n",
       "      <th>zero_infinity</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>BCELoss</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>BCEWithLogitsLoss</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CTCLoss</th>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CosineEmbeddingLoss</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>CrossEntropyLoss</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>GaussianNLLLoss</th>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HingeEmbeddingLoss</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>HuberLoss</th>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>KLDivLoss</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>L1Loss</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MSELoss</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MarginRankingLoss</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultiLabelMarginLoss</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultiLabelSoftMarginLoss</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>MultiMarginLoss</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>NLLLoss</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PoissonNLLLoss</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SmoothL1Loss</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>SoftMarginLoss</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TripletMarginLoss</th>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>TripletMarginWithDistanceLoss</th>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>PairwiseDistance</th>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td>x</td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "      <td></td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                              reduction reduce size_average margin weight eps  \\\n",
       "BCELoss                               x      x            x             x       \n",
       "BCEWithLogitsLoss                     x      x            x             x       \n",
       "CTCLoss                               x                                         \n",
       "CosineEmbeddingLoss                   x      x            x      x              \n",
       "CrossEntropyLoss                      x      x            x             x       \n",
       "GaussianNLLLoss                       x                                     x   \n",
       "HingeEmbeddingLoss                    x      x            x      x              \n",
       "HuberLoss                             x                                         \n",
       "KLDivLoss                             x      x            x                     \n",
       "L1Loss                                x      x            x                     \n",
       "MSELoss                               x      x            x                     \n",
       "MarginRankingLoss                     x      x            x      x              \n",
       "MultiLabelMarginLoss                  x      x            x                     \n",
       "MultiLabelSoftMarginLoss              x      x            x             x       \n",
       "MultiMarginLoss                       x      x            x      x      x       \n",
       "NLLLoss                               x      x            x             x       \n",
       "PoissonNLLLoss                        x      x            x                 x   \n",
       "SmoothL1Loss                          x      x            x                     \n",
       "SoftMarginLoss                        x      x            x                     \n",
       "TripletMarginLoss                     x      x            x      x          x   \n",
       "TripletMarginWithDistanceLoss         x                          x              \n",
       "PairwiseDistance                                                            x   \n",
       "\n",
       "                               p full ignore_index swap beta blank delta  \\\n",
       "BCELoss                                                                    \n",
       "BCEWithLogitsLoss                                                          \n",
       "CTCLoss                                                          x         \n",
       "CosineEmbeddingLoss                                                        \n",
       "CrossEntropyLoss                                 x                         \n",
       "GaussianNLLLoss                     x                                      \n",
       "HingeEmbeddingLoss                                                         \n",
       "HuberLoss                                                              x   \n",
       "KLDivLoss                                                                  \n",
       "L1Loss                                                                     \n",
       "MSELoss                                                                    \n",
       "MarginRankingLoss                                                          \n",
       "MultiLabelMarginLoss                                                       \n",
       "MultiLabelSoftMarginLoss                                                   \n",
       "MultiMarginLoss                x                                           \n",
       "NLLLoss                                          x                         \n",
       "PoissonNLLLoss                      x                                      \n",
       "SmoothL1Loss                                               x               \n",
       "SoftMarginLoss                                                             \n",
       "TripletMarginLoss              x                      x                    \n",
       "TripletMarginWithDistanceLoss                         x                    \n",
       "PairwiseDistance               x                                           \n",
       "\n",
       "                              distance_function keepdim label_smoothing  \\\n",
       "BCELoss                                                                   \n",
       "BCEWithLogitsLoss                                                         \n",
       "CTCLoss                                                                   \n",
       "CosineEmbeddingLoss                                                       \n",
       "CrossEntropyLoss                                                      x   \n",
       "GaussianNLLLoss                                                           \n",
       "HingeEmbeddingLoss                                                        \n",
       "HuberLoss                                                                 \n",
       "KLDivLoss                                                                 \n",
       "L1Loss                                                                    \n",
       "MSELoss                                                                   \n",
       "MarginRankingLoss                                                         \n",
       "MultiLabelMarginLoss                                                      \n",
       "MultiLabelSoftMarginLoss                                                  \n",
       "MultiMarginLoss                                                           \n",
       "NLLLoss                                                                   \n",
       "PoissonNLLLoss                                                            \n",
       "SmoothL1Loss                                                              \n",
       "SoftMarginLoss                                                            \n",
       "TripletMarginLoss                                                         \n",
       "TripletMarginWithDistanceLoss                 x                           \n",
       "PairwiseDistance                                      x                   \n",
       "\n",
       "                              log_input log_target pos_weight zero_infinity  \n",
       "BCELoss                                                                      \n",
       "BCEWithLogitsLoss                                           x                \n",
       "CTCLoss                                                                   x  \n",
       "CosineEmbeddingLoss                                                          \n",
       "CrossEntropyLoss                                                             \n",
       "GaussianNLLLoss                                                              \n",
       "HingeEmbeddingLoss                                                           \n",
       "HuberLoss                                                                    \n",
       "KLDivLoss                                        x                           \n",
       "L1Loss                                                                       \n",
       "MSELoss                                                                      \n",
       "MarginRankingLoss                                                            \n",
       "MultiLabelMarginLoss                                                         \n",
       "MultiLabelSoftMarginLoss                                                     \n",
       "MultiMarginLoss                                                              \n",
       "NLLLoss                                                                      \n",
       "PoissonNLLLoss                        x                                      \n",
       "SmoothL1Loss                                                                 \n",
       "SoftMarginLoss                                                               \n",
       "TripletMarginLoss                                                            \n",
       "TripletMarginWithDistanceLoss                                                \n",
       "PairwiseDistance                                                             "
      ]
     },
     "execution_count": 287,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_loss_data()\n",
    "data\n",
    "get_comparison_checkboxes(data, 'torch').T"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9cc3e992-1eaa-4e63-913f-04cd260285b4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
