{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 552,
   "id": "4075517e-3967-403c-bff6-005582374c48",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import inspect\n",
    "import re\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "from tensorflow import keras  # noqa: F401\n",
    "from keras import optimizers as tfoptim\n",
    "from keras import losses as tfloss\n",
    "from keras import metrics as tfmetric\n",
    "\n",
    "import torch\n",
    "import torch.optim as torchoptim\n",
    "import torch.nn.modules.loss as torchloss\n",
    "import torchmetrics as torchmetric\n",
    "\n",
    "import pandas as pd\n",
    "pd.set_option('display.max_colwidth', 500)\n",
    "\n",
    "import flatiron.core.tools as fict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 578,
   "id": "db3144b2-94d8-4baf-9d91-1711572a1690",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# TF----------------------------------------------------------------------\n",
      "class TFBaseConfig(BaseConfig):\n",
      "    name: str \n",
      "\n",
      "\n",
      "# HELPERS----------------------------------------------------------------------\n",
      "class UNIVERSAL(pyd.BaseModel):\n",
      "    dtype: Any = None \n",
      "\n",
      "\n",
      "class UNIVERSAL(pyd.BaseModel):\n",
      "    name: Any = None \n",
      "\n",
      "\n",
      "class TFAxis(pyd.BaseModel):\n",
      "    axis: Any = -1 \n",
      "\n",
      "\n",
      "class TFThresh(pyd.BaseModel):\n",
      "    thresholds: Any = None \n",
      "\n",
      "\n",
      "class TFClsId(pyd.BaseModel):\n",
      "    class_id: Any = None \n",
      "\n",
      "\n",
      "class TFNumThresh(pyd.BaseModel):\n",
      "    num_thresholds: Any = 200 \n",
      "\n",
      "\n",
      "# ------------------------------------------------------------------------------\n",
      "class TFMetricAUC(TFBaseConfig, TFNumThresh, TFThresh, UNIVERSAL, UNIVERSAL):\n",
      "    curve: Any = ROC\n",
      "    from_logits: Any = False\n",
      "    label_weights: Any = None\n",
      "    multi_label: Any = False\n",
      "    num_labels: Any = None\n",
      "    summation_method: Any = interpolation \n",
      "\n",
      "\n",
      "class TFMetricAccuracy(TFBaseConfig, UNIVERSAL, UNIVERSAL):\n",
      "    pass \n",
      "\n",
      "\n",
      "class TFMetricBinaryAccuracy(TFBaseConfig, UNIVERSAL, UNIVERSAL):\n",
      "    threshold: Any = 0.5 \n",
      "\n",
      "\n",
      "class TFMetricBinaryCrossentropy(TFBaseConfig, UNIVERSAL, UNIVERSAL):\n",
      "    from_logits: Any = False\n",
      "    label_smoothing: Any = 0 \n",
      "\n",
      "\n",
      "class TFMetricBinaryIoU(TFBaseConfig, UNIVERSAL, UNIVERSAL):\n",
      "    target_class_ids: Any = (0, 1)\n",
      "    threshold: Any = 0.5 \n",
      "\n",
      "\n",
      "class TFMetricCategoricalAccuracy(TFBaseConfig, UNIVERSAL, UNIVERSAL):\n",
      "    pass \n",
      "\n",
      "\n",
      "class TFMetricCategoricalCrossentropy(TFBaseConfig, TFAxis, UNIVERSAL, UNIVERSAL):\n",
      "    from_logits: Any = False\n",
      "    label_smoothing: Any = 0 \n",
      "\n",
      "\n",
      "class TFMetricCategoricalHinge(TFBaseConfig, UNIVERSAL, UNIVERSAL):\n",
      "    pass \n",
      "\n",
      "\n",
      "class TFMetricConcordanceCorrelation(TFBaseConfig, TFAxis, UNIVERSAL, UNIVERSAL):\n",
      "    pass \n",
      "\n",
      "\n",
      "class TFMetricCosineSimilarity(TFBaseConfig, TFAxis, UNIVERSAL, UNIVERSAL):\n",
      "    pass \n",
      "\n",
      "\n",
      "class TFMetricF1Score(TFBaseConfig, UNIVERSAL, UNIVERSAL):\n",
      "    average: Any = None\n",
      "    threshold: Any = None \n",
      "\n",
      "\n",
      "class TFMetricFBetaScore(TFBaseConfig, UNIVERSAL, UNIVERSAL):\n",
      "    average: Any = None\n",
      "    beta: Any = 1.0\n",
      "    threshold: Any = None \n",
      "\n",
      "\n",
      "class TFMetricFalseNegatives(TFBaseConfig, TFThresh, UNIVERSAL, UNIVERSAL):\n",
      "    pass \n",
      "\n",
      "\n",
      "class TFMetricFalsePositives(TFBaseConfig, TFThresh, UNIVERSAL, UNIVERSAL):\n",
      "    pass \n",
      "\n",
      "\n",
      "class TFMetricHinge(TFBaseConfig, UNIVERSAL, UNIVERSAL):\n",
      "    pass \n",
      "\n",
      "\n",
      "class TFMetricIoU(TFBaseConfig, TFAxis, UNIVERSAL, UNIVERSAL):\n",
      "    ignore_class: Any = None\n",
      "    num_classes: Any\n",
      "    sparse_y_pred: Any = True\n",
      "    sparse_y_true: Any = True\n",
      "    target_class_ids: Any \n",
      "\n",
      "\n",
      "class TFMetricKLDivergence(TFBaseConfig, UNIVERSAL, UNIVERSAL):\n",
      "    pass \n",
      "\n",
      "\n",
      "class TFMetricLogCoshError(TFBaseConfig, UNIVERSAL, UNIVERSAL):\n",
      "    pass \n",
      "\n",
      "\n",
      "class TFMetricMean(TFBaseConfig, UNIVERSAL, UNIVERSAL):\n",
      "    pass \n",
      "\n",
      "\n",
      "class TFMetricMeanAbsoluteError(TFBaseConfig, UNIVERSAL, UNIVERSAL):\n",
      "    pass \n",
      "\n",
      "\n",
      "class TFMetricMeanAbsolutePercentageError(TFBaseConfig, UNIVERSAL, UNIVERSAL):\n",
      "    pass \n",
      "\n",
      "\n",
      "class TFMetricMeanIoU(TFBaseConfig, TFAxis, UNIVERSAL, UNIVERSAL):\n",
      "    ignore_class: Any = None\n",
      "    num_classes: Any\n",
      "    sparse_y_pred: Any = True\n",
      "    sparse_y_true: Any = True \n",
      "\n",
      "\n",
      "class TFMetricMeanMetricWrapper(TFBaseConfig, UNIVERSAL, UNIVERSAL):\n",
      "    fn: Any \n",
      "\n",
      "\n",
      "class TFMetricMeanSquaredError(TFBaseConfig, UNIVERSAL, UNIVERSAL):\n",
      "    pass \n",
      "\n",
      "\n",
      "class TFMetricMeanSquaredLogarithmicError(TFBaseConfig, UNIVERSAL, UNIVERSAL):\n",
      "    pass \n",
      "\n",
      "\n",
      "class TFMetricMetric(TFBaseConfig, UNIVERSAL, UNIVERSAL):\n",
      "    pass \n",
      "\n",
      "\n",
      "class TFMetricOneHotIoU(TFBaseConfig, TFAxis, UNIVERSAL, UNIVERSAL):\n",
      "    ignore_class: Any = None\n",
      "    num_classes: Any\n",
      "    sparse_y_pred: Any = False\n",
      "    target_class_ids: Any \n",
      "\n",
      "\n",
      "class TFMetricOneHotMeanIoU(TFBaseConfig, TFAxis, UNIVERSAL, UNIVERSAL):\n",
      "    ignore_class: Any = None\n",
      "    num_classes: Any\n",
      "    sparse_y_pred: Any = False \n",
      "\n",
      "\n",
      "class TFMetricPearsonCorrelation(TFBaseConfig, TFAxis, UNIVERSAL, UNIVERSAL):\n",
      "    pass \n",
      "\n",
      "\n",
      "class TFMetricPoisson(TFBaseConfig, UNIVERSAL, UNIVERSAL):\n",
      "    pass \n",
      "\n",
      "\n",
      "class TFMetricPrecision(TFBaseConfig, TFClsId, TFThresh, UNIVERSAL, UNIVERSAL):\n",
      "    top_k: Any = None \n",
      "\n",
      "\n",
      "class TFMetricPrecisionAtRecall(TFBaseConfig, TFClsId, TFNumThresh, UNIVERSAL, UNIVERSAL):\n",
      "    recall: Any \n",
      "\n",
      "\n",
      "class TFMetricR2Score(TFBaseConfig, UNIVERSAL, UNIVERSAL):\n",
      "    class_aggregation: Any = uniform_average\n",
      "    num_regressors: Any = 0 \n",
      "\n",
      "\n",
      "class TFMetricRecall(TFBaseConfig, TFClsId, TFThresh, UNIVERSAL, UNIVERSAL):\n",
      "    top_k: Any = None \n",
      "\n",
      "\n",
      "class TFMetricRecallAtPrecision(TFBaseConfig, TFClsId, TFNumThresh, UNIVERSAL, UNIVERSAL):\n",
      "    precision: Any \n",
      "\n",
      "\n",
      "class TFMetricRootMeanSquaredError(TFBaseConfig, UNIVERSAL, UNIVERSAL):\n",
      "    pass \n",
      "\n",
      "\n",
      "class TFMetricSensitivityAtSpecificity(TFBaseConfig, TFClsId, TFNumThresh, UNIVERSAL, UNIVERSAL):\n",
      "    specificity: Any \n",
      "\n",
      "\n",
      "class TFMetricSparseCategoricalAccuracy(TFBaseConfig, UNIVERSAL, UNIVERSAL):\n",
      "    pass \n",
      "\n",
      "\n",
      "class TFMetricSparseCategoricalCrossentropy(TFBaseConfig, TFAxis, UNIVERSAL, UNIVERSAL):\n",
      "    from_logits: Any = False \n",
      "\n",
      "\n",
      "class TFMetricSparseTopKCategoricalAccuracy(TFBaseConfig, UNIVERSAL, UNIVERSAL):\n",
      "    from_sorted_ids: Any = False\n",
      "    k: Any = 5 \n",
      "\n",
      "\n",
      "class TFMetricSpecificityAtSensitivity(TFBaseConfig, TFClsId, TFNumThresh, UNIVERSAL, UNIVERSAL):\n",
      "    sensitivity: Any \n",
      "\n",
      "\n",
      "class TFMetricSquaredHinge(TFBaseConfig, UNIVERSAL, UNIVERSAL):\n",
      "    pass \n",
      "\n",
      "\n",
      "class TFMetricSum(TFBaseConfig, UNIVERSAL, UNIVERSAL):\n",
      "    pass \n",
      "\n",
      "\n",
      "class TFMetricTopKCategoricalAccuracy(TFBaseConfig, UNIVERSAL, UNIVERSAL):\n",
      "    k: Any = 5 \n",
      "\n",
      "\n",
      "class TFMetricTrueNegatives(TFBaseConfig, TFThresh, UNIVERSAL, UNIVERSAL):\n",
      "    pass \n",
      "\n",
      "\n",
      "class TFMetricTruePositives(TFBaseConfig, TFThresh, UNIVERSAL, UNIVERSAL):\n",
      "    pass \n",
      "\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1769482/934884955.py:199: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  data['inherit'] = ''\n"
     ]
    }
   ],
   "source": [
    "def get_classes(module):\n",
    "    members = inspect.getmembers(module)\n",
    "    members = list(filter(lambda x: inspect.isclass(x[1]), members))\n",
    "    members = list(filter(lambda x: not x[0].startswith('_'), members))\n",
    "    classes = dict(members)\n",
    "    return classes\n",
    "\n",
    "def create_signature(arg, annotation, default):\n",
    "    if annotation == 'UNTYPED':\n",
    "        annotation = 'Any'\n",
    "    if default == 'REQUIRED':\n",
    "        default = ''\n",
    "    else:\n",
    "        default = f' = {default}'\n",
    "    return f'{arg}: {annotation}{default}'\n",
    "\n",
    "def get_init_signature_data(class_, remove=['self']):\n",
    "    sig = inspect.getfullargspec(class_)\n",
    "    args = sig.args\n",
    "    for item in remove:\n",
    "        args.remove(item)\n",
    "\n",
    "    if sig.defaults is not None:\n",
    "        d = len(args) - len(sig.defaults)\n",
    "        req = args[:d]\n",
    "        opt = args[d:]\n",
    "        args = {k: 'REQUIRED' for k in req}\n",
    "        opt = dict(zip(opt, sig.defaults))\n",
    "        args.update(opt)\n",
    "    else:\n",
    "        args = {k: 'REQUIRED' for k in args}\n",
    "    \n",
    "    if isinstance(sig.kwonlydefaults, dict):\n",
    "        args.update(sig.kwonlydefaults)\n",
    "    \n",
    "    anno = sig.annotations\n",
    "    for key, val in args.items():\n",
    "        if key in anno:\n",
    "            args[key] = (val, anno[key].__name__)\n",
    "        else:\n",
    "            args[key] = (val, 'UNTYPED')\n",
    "            \n",
    "    data = []\n",
    "    for arg, (default, type_) in args.items():\n",
    "        data.append(dict(\n",
    "            arg=arg,\n",
    "            default=default,\n",
    "            type_=type_,\n",
    "            signature=create_signature(arg, type_, default),\n",
    "        ))\n",
    "    return data\n",
    "\n",
    "def get_module_class_data(module):\n",
    "    classes = get_classes(module)\n",
    "    data = []\n",
    "    for name, item in classes.items():\n",
    "        try:\n",
    "            datum = get_init_signature_data(item)\n",
    "        except:\n",
    "            continue\n",
    "        for row in datum:\n",
    "            row['class_'] = name\n",
    "        data.extend(datum)\n",
    "        \n",
    "    cols = ['class_', 'arg', 'type_', 'default', 'signature']\n",
    "    data = pd.DataFrame(data, columns=cols)\n",
    "    data['library'] = module.__name__.split('.')[0]\n",
    "    data['module'] = module.__name__\n",
    "    cols.insert(0, 'library')\n",
    "    cols.insert(1, 'module')\n",
    "    data = data[cols]\n",
    "    \n",
    "    return data\n",
    "\n",
    "def _get_data(tf_module, torch_module):\n",
    "    tf_data = get_module_class_data(tf_module)\n",
    "    torch_data = get_module_class_data(torch_module)\n",
    "    data = pd.concat([tf_data, torch_data], axis=0)\n",
    "\n",
    "    mask = data.library == 'keras'\n",
    "    data.loc[mask, 'library'] = 'tf'\n",
    "    \n",
    "    mask = data.library == 'torchmetrics'\n",
    "    data.loc[mask, 'library'] = 'torch'\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_optimizer_data():\n",
    "    data = _get_data(tfoptim, torchoptim)\n",
    "\n",
    "    data['field'] = data['class_']\n",
    "    mask = data.field == 'Nadam'\n",
    "    data.loc[mask, 'field'] = 'NAdam'\n",
    "    \n",
    "    mask = data.class_.apply(lambda x: x not in ['Optimizer', 'LossScaleOptimizer'])\n",
    "    data = data[mask]\n",
    "    \n",
    "    mask = data.arg != 'params'\n",
    "    data = data[mask]\n",
    "\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "\n",
    "    return data\n",
    "\n",
    "def get_loss_data():\n",
    "    data = _get_data(tfloss, torchloss)    \n",
    "    mask = data.class_.apply(lambda x: x not in ['deprecated'])\n",
    "    data = data[mask]\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    return data\n",
    "\n",
    "def get_metric_data():\n",
    "    data = _get_data(tfmetric, torchmetric)    \n",
    "    mask = data.class_.apply(lambda x: x not in ['deprecated'])\n",
    "    data = data[mask]\n",
    "    data.reset_index(drop=True, inplace=True)\n",
    "    return data\n",
    "\n",
    "def get_class_definitions(data, library, base_class='BaseConfig'):\n",
    "    caplib = library.capitalize()\n",
    "    if library == 'tf':\n",
    "        caplib = 'TF'\n",
    "    data = data.copy()\n",
    "    data['config_name'] = data \\\n",
    "        .apply(lambda x: f'class {caplib}{x.class_}({base_class}):', axis=1) \\\n",
    "        .apply(lambda x: re.sub(' Tf', ' TF', x))\n",
    "    class_def = data \\\n",
    "        .groupby('config_name', as_index=False) \\\n",
    "        .signature.agg(lambda x: '    ' + '\\n    '.join(sorted(x)))\n",
    "    class_def = class_def \\\n",
    "        .apply(lambda x: f'{x.config_name}\\n{x.signature}', axis=1) \\\n",
    "        .apply(lambda x: re.sub(' +$', '', x))\n",
    "    return class_def.tolist()\n",
    "\n",
    "def get_comparison_data(data, mask=None):\n",
    "    data = data.copy()\n",
    "    if mask is not None:\n",
    "        mask = data.library == mask\n",
    "        data = data[mask]\n",
    "    data = data.groupby('arg', as_index=False)[['library', 'class_']].agg(lambda x: x.unique())\n",
    "    data['len_library'] = data.library.apply(len)\n",
    "    data['len_class'] = data.class_.apply(len)\n",
    "    data.sort_values(['len_class', 'len_library'], ascending=False, inplace=True)\n",
    "    return data\n",
    "\n",
    "def get_comparison_checkboxes(data, mask=None):\n",
    "    data = get_comparison_data(data, mask=mask)\n",
    "    output = data.class_.apply(lambda x: {k: k for k in x}).tolist()\n",
    "    index = data.arg.tolist()\n",
    "    output = pd.DataFrame(output, index=index).map(lambda x: '' if pd.isnull(x) else 'x')\n",
    "    return output\n",
    "\n",
    "def get_base_class_text(data, arg, class_, base_class, class_re, library):\n",
    "    mask = data.arg.apply(lambda x: x == arg)\n",
    "    temp = data[mask]\n",
    "    if len(temp) == 0:\n",
    "        raise ValueError(f'{arg} arg not found')\n",
    "    result = get_class_definitions(temp, library, base_class)[0]\n",
    "    result = re.sub(class_re, f'class {class_}', result)\n",
    "    return result\n",
    "\n",
    "def get_subclass_text(aux, library, class_, inherit, signature, descriptor):\n",
    "    caplib = library.capitalize()\n",
    "    if library == 'tf':\n",
    "        caplib = 'TF'\n",
    "    inherit = ', '.join(sorted(filter(lambda x: x != '', inherit)))\n",
    "    output = f'class {caplib}{descriptor}{class_}({caplib}BaseConfig, {inherit}):\\n    '\n",
    "    output = re.sub(r', \\)', ')', output)\n",
    "    regex = '|'.join(aux.keys())\n",
    "    regex = f'({regex}):'\n",
    "    if isinstance(signature, str):\n",
    "        signature = [signature]\n",
    "    signature = list(filter(lambda x: not re.search(regex, x), signature))\n",
    "    if signature == []:\n",
    "        output += 'pass'\n",
    "    else:\n",
    "        output += '\\n    '.join(sorted(signature))\n",
    "    output = re.sub(' +$', '', output)\n",
    "    return output\n",
    "\n",
    "def print_config_definitions(data, aux, library, descriptor):\n",
    "    caplib = library.capitalize()\n",
    "    if library == 'tf':\n",
    "        caplib = 'TF'\n",
    "    class_re = f'class {caplib}[a-zA-Z]*'\n",
    "\n",
    "    mask = data.library == library\n",
    "    data = data[mask]\n",
    "\n",
    "    # base class\n",
    "    base = get_class_definitions(data, library)[0].split('\\n')[0]\n",
    "    base = re.sub(class_re, f'class {caplib}BaseConfig', base)\n",
    "    base += '\\n    name: str'\n",
    "    print(f'# {library.upper()}' + '-' * 70)\n",
    "    print(base, '\\n\\n')\n",
    "\n",
    "    # helper classes\n",
    "    print('# HELPERS' + '-' * 70)\n",
    "    data['inherit'] = ''\n",
    "    for arg, cls_ in aux.items():\n",
    "        text = get_base_class_text(data, arg, cls_, 'pyd.BaseModel', class_re, library)\n",
    "        print(text, '\\n\\n')\n",
    "        mask = data.arg == arg\n",
    "        data.loc[mask, 'inherit'] = cls_\n",
    "\n",
    "    # subclasses\n",
    "    print('# ' + '-' * 78)\n",
    "    class_def = data \\\n",
    "        .sort_values('class_') \\\n",
    "        .groupby('class_', as_index=False)[['inherit', 'signature']] \\\n",
    "        .agg(lambda x: x) \\\n",
    "        .apply(lambda x: get_subclass_text(\n",
    "            aux, library, x.class_, x.inherit, x.signature, descriptor), axis=1\n",
    "        ).tolist()\n",
    "    for item in class_def:\n",
    "        print(item, '\\n\\n')\n",
    "\n",
    "print_tf_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 566,
   "id": "fc4d25f8-76e7-4713-89b3-6d21c667e0c1",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_tf_optimizer_config_definitions():\n",
    "    # TF\n",
    "    d = get_optimizer_data()\n",
    "    mask = d.library == 'tf'\n",
    "    d = d[mask]\n",
    "\n",
    "    # TFBaseConfig\n",
    "    tf_base_args = [\n",
    "        'clipnorm',\n",
    "        'clipvalue',\n",
    "        'ema_momentum',\n",
    "        'ema_overwrite_frequency',\n",
    "        'global_clipnorm',\n",
    "        'gradient_accumulation_steps',\n",
    "        'learning_rate',\n",
    "        'loss_scale_factor',\n",
    "        'name',\n",
    "        'use_ema',\n",
    "        'weight_decay',\n",
    "    ]\n",
    "    mask = d.arg.apply(lambda x: x in tf_base_args)\n",
    "    d0 = d[mask]\n",
    "    tf_base = get_class_definitions(d0)[0]\n",
    "    tf_base = re.sub('TFAdadeltaConfig', 'TFBaseConfig', tf_base)\n",
    "    print(tf_base, '\\n\\n')\n",
    "\n",
    "    # TFEpsilonBaseConfig\n",
    "    tf_eps_args = ['epsilon']\n",
    "    mask = d.arg.apply(lambda x: x in tf_eps_args)\n",
    "    d1 = d[mask]\n",
    "    tf_eps = get_class_definitions(d1, 'TFBaseConfig')[0]\n",
    "    tf_eps = re.sub('class TF[a-zA-Z]*Config', 'class TFEpsilonBaseConfig', tf_eps)\n",
    "    print(tf_eps, '\\n\\n')\n",
    "    \n",
    "    # TFEpsilonBaseConfig\n",
    "    tf_eps_args = ['epsilon']\n",
    "    mask = d.arg.apply(lambda x: x in tf_eps_args)\n",
    "    d1 = d[mask]\n",
    "    tf_eps = get_class_definitions(d1, 'TFBaseConfig')[0]\n",
    "    tf_eps = re.sub('class TF[a-zA-Z]*Config', 'class TFEpsilonBaseConfig', tf_eps)\n",
    "    print(tf_eps, '\\n\\n')\n",
    "\n",
    "    # TFBaseConfig subclasses\n",
    "    eps_classes = d1.class_.unique().tolist()\n",
    "    mask = d.class_.apply(lambda x: x in eps_classes)\n",
    "    d2 = d[~mask]\n",
    "    mask = d2.arg.apply(lambda x: x in tf_base_args)\n",
    "    d2 = d2[~mask]\n",
    "    tf_subclass = get_class_definitions(d2, 'TFBaseConfig')\n",
    "    for item in tf_subclass:\n",
    "        print(item, '\\n\\n')\n",
    "\n",
    "    # TFEpsilonBaseConfig subclasses\n",
    "    eps_classes = d1.class_.unique().tolist()\n",
    "    mask = d.class_.apply(lambda x: x in eps_classes)\n",
    "    d2 = d[mask]\n",
    "    mask = d2.arg.apply(lambda x: x in tf_base_args or x in tf_eps_args)\n",
    "    d2 = d2[~mask]\n",
    "    tf_eps_subclass = get_class_definitions(d2, 'TFEpsilonBaseConfig')\n",
    "    for item in tf_eps_subclass:\n",
    "        print(item, '\\n\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 591,
   "id": "68f2fcd9-a31a-4671-b138-451f78d7a5b5",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\u001b[0;31mInit signature:\u001b[0m\n",
       "\u001b[0mtfmetric\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mBinaryIoU\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mtarget_class_ids\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mthreshold\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m0.5\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m    \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\n",
       "\u001b[0;34m\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
       "\u001b[0;31mDocstring:\u001b[0m     \n",
       "Computes the Intersection-Over-Union metric for class 0 and/or 1.\n",
       "\n",
       "Formula:\n",
       "\n",
       "```python\n",
       "iou = true_positives / (true_positives + false_positives + false_negatives)\n",
       "```\n",
       "Intersection-Over-Union is a common evaluation metric for semantic image\n",
       "segmentation.\n",
       "\n",
       "To compute IoUs, the predictions are accumulated in a confusion matrix,\n",
       "weighted by `sample_weight` and the metric is then calculated from it.\n",
       "\n",
       "If `sample_weight` is `None`, weights default to 1.\n",
       "Use `sample_weight` of 0 to mask values.\n",
       "\n",
       "This class can be used to compute IoUs for a binary classification task\n",
       "where the predictions are provided as logits. First a `threshold` is applied\n",
       "to the predicted values such that those that are below the `threshold` are\n",
       "converted to class 0 and those that are above the `threshold` are converted\n",
       "to class 1.\n",
       "\n",
       "IoUs for classes 0 and 1 are then computed, the mean of IoUs for the classes\n",
       "that are specified by `target_class_ids` is returned.\n",
       "\n",
       "Note: with `threshold=0`, this metric has the same behavior as `IoU`.\n",
       "\n",
       "Args:\n",
       "    target_class_ids: A tuple or list of target class ids for which the\n",
       "        metric is returned. Options are `[0]`, `[1]`, or `[0, 1]`. With\n",
       "        `[0]` (or `[1]`), the IoU metric for class 0 (or class 1,\n",
       "        respectively) is returned. With `[0, 1]`, the mean of IoUs for the\n",
       "        two classes is returned.\n",
       "    threshold: A threshold that applies to the prediction logits to convert\n",
       "        them to either predicted class 0 if the logit is below `threshold`\n",
       "        or predicted class 1 if the logit is above `threshold`.\n",
       "    name: (Optional) string name of the metric instance.\n",
       "    dtype: (Optional) data type of the metric result.\n",
       "\n",
       "Example:\n",
       "\n",
       "Example:\n",
       "\n",
       ">>> m = keras.metrics.BinaryIoU(target_class_ids=[0, 1], threshold=0.3)\n",
       ">>> m.update_state([0, 1, 0, 1], [0.1, 0.2, 0.4, 0.7])\n",
       ">>> m.result()\n",
       "0.33333334\n",
       "\n",
       ">>> m.reset_state()\n",
       ">>> m.update_state([0, 1, 0, 1], [0.1, 0.2, 0.4, 0.7],\n",
       "...                sample_weight=[0.2, 0.3, 0.4, 0.1])\n",
       ">>> # cm = [[0.2, 0.4],\n",
       ">>> #        [0.3, 0.1]]\n",
       ">>> # sum_row = [0.6, 0.4], sum_col = [0.5, 0.5],\n",
       ">>> # true_positives = [0.2, 0.1]\n",
       ">>> # iou = [0.222, 0.125]\n",
       ">>> m.result()\n",
       "0.17361112\n",
       "\n",
       "Usage with `compile()` API:\n",
       "\n",
       "```python\n",
       "model.compile(\n",
       "    optimizer='sgd',\n",
       "    loss='mse',\n",
       "    metrics=[keras.metrics.BinaryIoU(\n",
       "        target_class_ids=[0],\n",
       "        threshold=0.5\n",
       "    )]\n",
       ")\n",
       "```\n",
       "\u001b[0;31mFile:\u001b[0m           ~/pdm/envs/pdm-kVbOHlCT-dev-3.10/lib/python3.10/site-packages/keras/src/metrics/iou_metrics.py\n",
       "\u001b[0;31mType:\u001b[0m           type\n",
       "\u001b[0;31mSubclasses:\u001b[0m     "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# tfmetric.OneHotIoU?\n",
    "# tfmetric.OneHotMeanIoU?\n",
    "tfmetric.Precision?\n",
    "tfmetric.PrecisionAtRecall?\n",
    "tfmetric.R2Score?\n",
    "# tfmetric.Recall?\n",
    "# tfmetric.RecallAtPrecision?\n",
    "tfmetric.SensitivityAtSpecificity?\n",
    "tfmetric.BinaryIoU?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 567,
   "id": "a31669d6-1cbb-4915-b81c-1c5224dc9f24",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# def print_tf_loss():\n",
    "#     data = get_loss_data()\n",
    "#     aux = dict(\n",
    "#         reduction='TReduct',\n",
    "#         reduce='TRed',\n",
    "#         size_average='TSize',\n",
    "#         margin='TMarg',\n",
    "#         weight='TWeight',\n",
    "#         eps='TEps',\n",
    "#     )\n",
    "#     print_config_definitions(data, aux, 'tf', 'Loss')\n",
    "\n",
    "# def print_tf_optimizer():\n",
    "#     data = get_optimizer_data()\n",
    "#     aux = dict(\n",
    "#         lr='TLR',\n",
    "#         maximize='TMax',\n",
    "#         foreach='TFor',\n",
    "#         differentiable='TDiff',\n",
    "#         eps='TEps',\n",
    "#         capturable='TCap',\n",
    "#         weight_decay='TDecay',\n",
    "#     )\n",
    "#     print_config_definitions(data, aux, 'tf', 'Opt')\n",
    "    \n",
    "def print_tf_metric():\n",
    "    data = get_metric_data()\n",
    "    aux = dict(\n",
    "        dtype='UNIVERSAL',\n",
    "        name='UNIVERSAL',\n",
    "        axis='TFAxis',\n",
    "        thresholds='TFThresh',\n",
    "        class_id='TFClsId',\n",
    "        num_thresholds='TFNumThresh',\n",
    "    )\n",
    "    print_config_definitions(data, aux, 'tf', 'Metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 568,
   "id": "4c622127-b00a-4a63-ae66-074c61349810",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def print_torch_loss():\n",
    "    data = get_loss_data()\n",
    "    aux = dict(\n",
    "        reduction='TReduct',\n",
    "        reduce='TRed',\n",
    "        size_average='TSize',\n",
    "        margin='TMarg',\n",
    "        weight='TWeight',\n",
    "        eps='TEps',\n",
    "    )\n",
    "    print_config_definitions(data, aux, 'torch', 'Loss')\n",
    "\n",
    "def print_torch_optimizer():\n",
    "    data = get_optimizer_data()\n",
    "    aux = dict(\n",
    "        lr='TLR',\n",
    "        maximize='TMax',\n",
    "        foreach='TFor',\n",
    "        differentiable='TDiff',\n",
    "        eps='TEps',\n",
    "        capturable='TCap',\n",
    "        weight_decay='TDecay',\n",
    "    )\n",
    "    print_config_definitions(data, aux, 'torch', 'Opt')\n",
    "    \n",
    "def print_torch_metric():\n",
    "    data = get_metric_data()\n",
    "    aux = dict(\n",
    "        ignore_index='TInd',\n",
    "        num_outputs='TOut',\n",
    "        top_k='TTopK',\n",
    "    )\n",
    "    print_config_definitions(data, aux, 'torch', 'Metric')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 569,
   "id": "6c8455d9-718a-4d86-aced-2af4e9192e01",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "# print_torch_optimizer()\n",
    "# print_torch_loss()\n",
    "# print_torch_metric()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 540,
   "id": "fa163fa7-3762-4ba1-af16-7fe8edfecba0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>arg</th>\n",
       "      <th>library</th>\n",
       "      <th>class_</th>\n",
       "      <th>len_library</th>\n",
       "      <th>len_class</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>dtype</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[AUC, Accuracy, BinaryAccuracy, BinaryCrossentropy, BinaryIoU, CategoricalAccuracy, CategoricalCrossentropy, CategoricalHinge, ConcordanceCorrelation, CosineSimilarity, F1Score, FBetaScore, FalseNegatives, FalsePositives, Hinge, IoU, KLDivergence, LogCoshError, Mean, MeanAbsoluteError, MeanAbsolutePercentageError, MeanIoU, MeanMetricWrapper, MeanSquaredError, MeanSquaredLogarithmicError, Metric, OneHotIoU, OneHotMeanIoU, PearsonCorrelation, Poisson, Precision, PrecisionAtRecall, R2Score, Rec...</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>name</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[AUC, Accuracy, BinaryAccuracy, BinaryCrossentropy, BinaryIoU, CategoricalAccuracy, CategoricalCrossentropy, CategoricalHinge, ConcordanceCorrelation, CosineSimilarity, F1Score, FBetaScore, FalseNegatives, FalsePositives, Hinge, IoU, KLDivergence, LogCoshError, Mean, MeanAbsoluteError, MeanAbsolutePercentageError, MeanIoU, MeanMetricWrapper, MeanSquaredError, MeanSquaredLogarithmicError, Metric, OneHotIoU, OneHotMeanIoU, PearsonCorrelation, Poisson, Precision, PrecisionAtRecall, R2Score, Rec...</td>\n",
       "      <td>1</td>\n",
       "      <td>46</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>axis</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[CategoricalCrossentropy, ConcordanceCorrelation, CosineSimilarity, IoU, MeanIoU, OneHotIoU, OneHotMeanIoU, PearsonCorrelation, SparseCategoricalCrossentropy]</td>\n",
       "      <td>1</td>\n",
       "      <td>9</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>thresholds</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[AUC, FalseNegatives, FalsePositives, Precision, Recall, TrueNegatives, TruePositives]</td>\n",
       "      <td>1</td>\n",
       "      <td>7</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>class_id</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[Precision, PrecisionAtRecall, Recall, RecallAtPrecision, SensitivityAtSpecificity, SpecificityAtSensitivity]</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>num_thresholds</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[AUC, PrecisionAtRecall, RecallAtPrecision, SensitivityAtSpecificity, SpecificityAtSensitivity]</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>from_logits</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[AUC, BinaryCrossentropy, CategoricalCrossentropy, SparseCategoricalCrossentropy]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>ignore_class</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[IoU, MeanIoU, OneHotIoU, OneHotMeanIoU]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>num_classes</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[IoU, MeanIoU, OneHotIoU, OneHotMeanIoU]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>sparse_y_pred</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[IoU, MeanIoU, OneHotIoU, OneHotMeanIoU]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>threshold</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[BinaryAccuracy, BinaryIoU, F1Score, FBetaScore]</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>target_class_ids</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[BinaryIoU, IoU, OneHotIoU]</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>average</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[F1Score, FBetaScore]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>k</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[SparseTopKCategoricalAccuracy, TopKCategoricalAccuracy]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>label_smoothing</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[BinaryCrossentropy, CategoricalCrossentropy]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>sparse_y_true</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[IoU, MeanIoU]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>30</th>\n",
       "      <td>top_k</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[Precision, Recall]</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>beta</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[FBetaScore]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>class_aggregation</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[R2Score]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>curve</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[AUC]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>fn</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[MeanMetricWrapper]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>from_sorted_ids</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[SparseTopKCategoricalAccuracy]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>label_weights</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[AUC]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>multi_label</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[AUC]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>num_labels</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[AUC]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>num_regressors</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[R2Score]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>precision</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[RecallAtPrecision]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>recall</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[PrecisionAtRecall]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>sensitivity</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[SpecificityAtSensitivity]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>specificity</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[SensitivityAtSpecificity]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>summation_method</td>\n",
       "      <td>[tf]</td>\n",
       "      <td>[AUC]</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                  arg library  \\\n",
       "6               dtype    [tf]   \n",
       "15               name    [tf]   \n",
       "1                axis    [tf]   \n",
       "29         thresholds    [tf]   \n",
       "4            class_id    [tf]   \n",
       "19     num_thresholds    [tf]   \n",
       "8         from_logits    [tf]   \n",
       "10       ignore_class    [tf]   \n",
       "16        num_classes    [tf]   \n",
       "23      sparse_y_pred    [tf]   \n",
       "28          threshold    [tf]   \n",
       "27   target_class_ids    [tf]   \n",
       "0             average    [tf]   \n",
       "11                  k    [tf]   \n",
       "12    label_smoothing    [tf]   \n",
       "24      sparse_y_true    [tf]   \n",
       "30              top_k    [tf]   \n",
       "2                beta    [tf]   \n",
       "3   class_aggregation    [tf]   \n",
       "5               curve    [tf]   \n",
       "7                  fn    [tf]   \n",
       "9     from_sorted_ids    [tf]   \n",
       "13      label_weights    [tf]   \n",
       "14        multi_label    [tf]   \n",
       "17         num_labels    [tf]   \n",
       "18     num_regressors    [tf]   \n",
       "20          precision    [tf]   \n",
       "21             recall    [tf]   \n",
       "22        sensitivity    [tf]   \n",
       "25        specificity    [tf]   \n",
       "26   summation_method    [tf]   \n",
       "\n",
       "                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 class_  \\\n",
       "6   [AUC, Accuracy, BinaryAccuracy, BinaryCrossentropy, BinaryIoU, CategoricalAccuracy, CategoricalCrossentropy, CategoricalHinge, ConcordanceCorrelation, CosineSimilarity, F1Score, FBetaScore, FalseNegatives, FalsePositives, Hinge, IoU, KLDivergence, LogCoshError, Mean, MeanAbsoluteError, MeanAbsolutePercentageError, MeanIoU, MeanMetricWrapper, MeanSquaredError, MeanSquaredLogarithmicError, Metric, OneHotIoU, OneHotMeanIoU, PearsonCorrelation, Poisson, Precision, PrecisionAtRecall, R2Score, Rec...   \n",
       "15  [AUC, Accuracy, BinaryAccuracy, BinaryCrossentropy, BinaryIoU, CategoricalAccuracy, CategoricalCrossentropy, CategoricalHinge, ConcordanceCorrelation, CosineSimilarity, F1Score, FBetaScore, FalseNegatives, FalsePositives, Hinge, IoU, KLDivergence, LogCoshError, Mean, MeanAbsoluteError, MeanAbsolutePercentageError, MeanIoU, MeanMetricWrapper, MeanSquaredError, MeanSquaredLogarithmicError, Metric, OneHotIoU, OneHotMeanIoU, PearsonCorrelation, Poisson, Precision, PrecisionAtRecall, R2Score, Rec...   \n",
       "1                                                                                                                                                                                                                                                                                                                                                        [CategoricalCrossentropy, ConcordanceCorrelation, CosineSimilarity, IoU, MeanIoU, OneHotIoU, OneHotMeanIoU, PearsonCorrelation, SparseCategoricalCrossentropy]   \n",
       "29                                                                                                                                                                                                                                                                                                                                                                                                                               [AUC, FalseNegatives, FalsePositives, Precision, Recall, TrueNegatives, TruePositives]   \n",
       "4                                                                                                                                                                                                                                                                                                                                                                                                         [Precision, PrecisionAtRecall, Recall, RecallAtPrecision, SensitivityAtSpecificity, SpecificityAtSensitivity]   \n",
       "19                                                                                                                                                                                                                                                                                                                                                                                                                      [AUC, PrecisionAtRecall, RecallAtPrecision, SensitivityAtSpecificity, SpecificityAtSensitivity]   \n",
       "8                                                                                                                                                                                                                                                                                                                                                                                                                                     [AUC, BinaryCrossentropy, CategoricalCrossentropy, SparseCategoricalCrossentropy]   \n",
       "10                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [IoU, MeanIoU, OneHotIoU, OneHotMeanIoU]   \n",
       "16                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [IoU, MeanIoU, OneHotIoU, OneHotMeanIoU]   \n",
       "23                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [IoU, MeanIoU, OneHotIoU, OneHotMeanIoU]   \n",
       "28                                                                                                                                                                                                                                                                                                                                                                                                                                                                     [BinaryAccuracy, BinaryIoU, F1Score, FBetaScore]   \n",
       "27                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          [BinaryIoU, IoU, OneHotIoU]   \n",
       "0                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [F1Score, FBetaScore]   \n",
       "11                                                                                                                                                                                                                                                                                                                                                                                                                                                             [SparseTopKCategoricalAccuracy, TopKCategoricalAccuracy]   \n",
       "12                                                                                                                                                                                                                                                                                                                                                                                                                                                                        [BinaryCrossentropy, CategoricalCrossentropy]   \n",
       "24                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [IoU, MeanIoU]   \n",
       "30                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [Precision, Recall]   \n",
       "2                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                          [FBetaScore]   \n",
       "3                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                             [R2Score]   \n",
       "5                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                 [AUC]   \n",
       "7                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                   [MeanMetricWrapper]   \n",
       "9                                                                                                                                                                                                                                                                                                                                                                                                                                                                                       [SparseTopKCategoricalAccuracy]   \n",
       "13                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [AUC]   \n",
       "14                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [AUC]   \n",
       "17                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [AUC]   \n",
       "18                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                            [R2Score]   \n",
       "20                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [RecallAtPrecision]   \n",
       "21                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                  [PrecisionAtRecall]   \n",
       "22                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [SpecificityAtSensitivity]   \n",
       "25                                                                                                                                                                                                                                                                                                                                                                                                                                                                                           [SensitivityAtSpecificity]   \n",
       "26                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                                [AUC]   \n",
       "\n",
       "    len_library  len_class  \n",
       "6             1         46  \n",
       "15            1         46  \n",
       "1             1          9  \n",
       "29            1          7  \n",
       "4             1          6  \n",
       "19            1          5  \n",
       "8             1          4  \n",
       "10            1          4  \n",
       "16            1          4  \n",
       "23            1          4  \n",
       "28            1          4  \n",
       "27            1          3  \n",
       "0             1          2  \n",
       "11            1          2  \n",
       "12            1          2  \n",
       "24            1          2  \n",
       "30            1          2  \n",
       "2             1          1  \n",
       "3             1          1  \n",
       "5             1          1  \n",
       "7             1          1  \n",
       "9             1          1  \n",
       "13            1          1  \n",
       "14            1          1  \n",
       "17            1          1  \n",
       "18            1          1  \n",
       "20            1          1  \n",
       "21            1          1  \n",
       "22            1          1  \n",
       "25            1          1  \n",
       "26            1          1  "
      ]
     },
     "execution_count": 540,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_metric_data()\n",
    "# data = data[data.class_.apply(lambda x: x in clss)]\n",
    "# data.groupby('class_').arg.unique()\n",
    "get_comparison_checkboxes(data, 'tf').T\n",
    "get_comparison_data(data, 'tf')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 454,
   "id": "c904975d-b584-40f2-b6c8-49668660cb01",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['empty_target_action: str = neg',\n",
       " 'empty_target_action: str = neg',\n",
       " 'empty_target_action: str = neg',\n",
       " 'empty_target_action: str = neg',\n",
       " 'empty_target_action: str = neg',\n",
       " 'empty_target_action: str = neg',\n",
       " 'empty_target_action: str = neg',\n",
       " 'empty_target_action: str = neg',\n",
       " 'empty_target_action: str = neg',\n",
       " 'empty_target_action: str = pos',\n",
       " 'kernel_size: Sequence = (11, 11)',\n",
       " 'kernel_size: Union = 11',\n",
       " 'kernel_size: Union = 11',\n",
       " 'lowercase: bool = False',\n",
       " 'lowercase: bool = False',\n",
       " 'lowercase: bool = True',\n",
       " 'metric: Metric',\n",
       " 'metric: Union',\n",
       " 'mode: Literal = counts',\n",
       " 'mode: Literal = speaker-wise',\n",
       " 'multioutput: Literal = uniform_average',\n",
       " 'multioutput: str = uniform_average',\n",
       " 'nan_strategy: Literal = replace',\n",
       " 'nan_strategy: Literal = replace',\n",
       " 'nan_strategy: Literal = replace',\n",
       " 'nan_strategy: Literal = replace',\n",
       " 'nan_strategy: Union = warn',\n",
       " 'nan_strategy: Union = warn',\n",
       " 'nan_strategy: Union = warn',\n",
       " 'nan_strategy: Union = warn',\n",
       " 'nan_strategy: Union = warn',\n",
       " 'nan_strategy: Union = warn',\n",
       " 'nan_strategy: Union = warn',\n",
       " 'normalize: Literal = relu',\n",
       " 'normalize: bool = False',\n",
       " 'num_classes: Any',\n",
       " 'num_classes: Any',\n",
       " 'num_classes: Any',\n",
       " 'num_classes: Any',\n",
       " 'num_classes: Optional = None',\n",
       " 'num_classes: int',\n",
       " 'num_classes: int',\n",
       " 'num_classes: int',\n",
       " 'num_classes: int',\n",
       " 'num_outputs: int',\n",
       " 'num_outputs: int = 1',\n",
       " 'num_outputs: int = 1',\n",
       " 'num_outputs: int = 1',\n",
       " 'num_outputs: int = 1',\n",
       " 'num_outputs: int = 1',\n",
       " 'num_outputs: int = 1',\n",
       " 'num_outputs: int = 1',\n",
       " 'num_outputs: int = 1',\n",
       " 'num_outputs: int = 1',\n",
       " 'p: float',\n",
       " 'p: int = 1',\n",
       " 'reduction: Literal = elementwise_mean',\n",
       " 'reduction: Literal = elementwise_mean',\n",
       " 'reduction: Literal = elementwise_mean',\n",
       " 'reduction: Literal = elementwise_mean',\n",
       " 'reduction: Literal = elementwise_mean',\n",
       " 'reduction: Literal = elementwise_mean',\n",
       " 'reduction: Literal = elementwise_mean',\n",
       " 'reduction: Literal = mean',\n",
       " 'reduction: Literal = sum',\n",
       " 'reduction: Literal = sum',\n",
       " 'sigma: Sequence = (1.5, 1.5)',\n",
       " 'sigma: Union = 1.5',\n",
       " 'sigma: Union = 1.5',\n",
       " 'threshold: Any = 0.5',\n",
       " 'threshold: Any = 0.5',\n",
       " 'threshold: Any = None',\n",
       " 'threshold: Any = None',\n",
       " 'threshold: float',\n",
       " 'threshold: float = 0.5']"
      ]
     },
     "execution_count": 454,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = get_metric_data()\n",
    "x = get_comparison_checkboxes(data, 'torch')\n",
    "x.map(lambda x: np.nan if x == '' else x).loc['empty_target_action'].dropna()\n",
    "\n",
    "x = data[data.library == 'torch'].groupby('arg', as_index=False).signature.nunique()\n",
    "multi_sig_args = x[x.signature > 1].arg.tolist()\n",
    "sorted(data[data.arg.apply(lambda x: x in multi_sig_args)].signature.tolist())\n",
    "# .T.map(lambda x: 1 if x == 'x' else 0).sum().head(40)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 535,
   "id": "bbec2caa-4e1f-4abf-9583-ee1f68c8b800",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'flatiron.core.torch_config' from '/home/ubuntu/flatiron/python/flatiron/core/torch_config.py'>"
      ]
     },
     "execution_count": 535,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import flatiron.core.torch_config as fi_torch\n",
    "fi_torch.TorchMet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "509f8d27-530e-4a4f-b616-572ac276cec5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
