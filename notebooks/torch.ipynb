{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "74136b3a-292d-44c3-8b07-b317828a4fb0",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-02-18 02:25:29.576723: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1739845529.593245  104060 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1739845529.598290  104060 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2025-02-18 02:25:29.615743: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "import os\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "from torch import nn\n",
    "\n",
    "import flatiron.torch.tools as fi_torchtools\n",
    "from flatiron.core.dataset import Dataset\n",
    "from flatiron.torch.tools_test import SimpleModel\n",
    "import cv_depot.api as cvd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "570391d9-b7b6-4cbd-b7dc-1f50f74a8d61",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.optim.sgd.SGD"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import flatiron\n",
    "opt = flatiron.torch.optimizer.get('SGD')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ad8b0118-f15a-458b-9f2b-18eef2593279",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "Adam.__init__() missing 1 required positional argument: 'params'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m model \u001b[38;5;241m=\u001b[39m SimpleModel(\u001b[38;5;241m2\u001b[39m, \u001b[38;5;241m1\u001b[39m, \u001b[38;5;241m2\u001b[39m)\n\u001b[0;32m----> 2\u001b[0m compiled \u001b[38;5;241m=\u001b[39m \u001b[43mfi_torchtools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcompile\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmodel\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mmodel\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAdam\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloss\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mCrossEntropyLoss\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mmetrics\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mAccuracy\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcuda\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mdict\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mreduce-overhead\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/flatiron/python/flatiron/torch/tools.py:61\u001b[0m, in \u001b[0;36mcompile\u001b[0;34m(model, optimizer, loss, metrics, device, kwargs)\u001b[0m\n\u001b[1;32m     43\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;21mcompile\u001b[39m(model, optimizer, loss, metrics, device, kwargs):\n\u001b[1;32m     44\u001b[0m     \u001b[38;5;66;03m# type: (Any, str, str, list[str], str, dict[str, Any]) -> dict[str, Any]\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m'''\u001b[39;00m\n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    Call `torch.compile` on given model with kwargs.\u001b[39;00m\n\u001b[1;32m     47\u001b[0m \n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     57\u001b[0m \u001b[38;5;124;03m        dict: Dict of compiled objects.\u001b[39;00m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;124;03m    '''\u001b[39;00m\n\u001b[1;32m     59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m     60\u001b[0m         model\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mcompile(model, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs),\n\u001b[0;32m---> 61\u001b[0m         optimizer\u001b[38;5;241m=\u001b[39m\u001b[43mflatiron\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mget\u001b[49m\u001b[43m(\u001b[49m\u001b[43moptimizer\u001b[49m\u001b[43m)\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m,\n\u001b[1;32m     62\u001b[0m         loss\u001b[38;5;241m=\u001b[39mflatiron\u001b[38;5;241m.\u001b[39mtorch\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mget(loss)(),\n\u001b[1;32m     63\u001b[0m         metrics\u001b[38;5;241m=\u001b[39m[flatiron\u001b[38;5;241m.\u001b[39mtorch\u001b[38;5;241m.\u001b[39mmetric\u001b[38;5;241m.\u001b[39mget(m)() \u001b[38;5;28;01mfor\u001b[39;00m m \u001b[38;5;129;01min\u001b[39;00m metrics],\n\u001b[1;32m     64\u001b[0m         device\u001b[38;5;241m=\u001b[39mdevice,\n\u001b[1;32m     65\u001b[0m     )\n",
      "\u001b[0;31mTypeError\u001b[0m: Adam.__init__() missing 1 required positional argument: 'params'"
     ]
    }
   ],
   "source": [
    "model = SimpleModel(2, 1, 2)\n",
    "compiled = fi_torchtools.compile(\n",
    "    model=model, optimizer='Adam', loss='CrossEntropyLoss',\n",
    "    metrics=['Accuracy'], device='cuda', kwargs=dict(mode='reduce-overhead')\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "aa257c9a-a61e-4f8b-90ce-522835f5d9c1",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "src = '/mnt/storage/projects/unet001/dset002/p-unet001_s-dset002_d-glom_v001'\n",
    "data = Dataset.read_directory(src, labels=['a'])\n",
    "train, test = data.train_test_split()\n",
    "# train = fi_torchtools.TorchDataset.monkey_patch(train)\n",
    "# test = fi_torchtools.TorchDataset.monkey_patch(test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d548b65a-c3b8-4259-80f2-a311417d314f",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'model': OptimizedModule(\n",
       "   (_orig_mod): SimpleModel(\n",
       "     (layer_stack): Sequential(\n",
       "       (0): Flatten(start_dim=1, end_dim=-1)\n",
       "       (1): Linear(in_features=2, out_features=1, bias=True)\n",
       "       (2): Linear(in_features=1, out_features=2, bias=True)\n",
       "     )\n",
       "   )\n",
       " ),\n",
       " 'optimizer': torch.optim.adam.Adam,\n",
       " 'loss': torch.nn.modules.loss.CrossEntropyLoss,\n",
       " 'metrics': [torchmetrics.classification.accuracy.Accuracy],\n",
       " 'device': 'cuda'}"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compiled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f95c23f4-e35f-4279-a378-70128b7fb467",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d5601982ca814a038187118a3bbc3059",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/50 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "TypeError",
     "evalue": "Optimizer.zero_grad() missing 1 required positional argument: 'self'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[8], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[43mfi_torchtools\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtrain\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcompiled\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m    \u001b[49m\u001b[43m[\u001b[49m\u001b[43m]\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtrain\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtest\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m10\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m42\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/flatiron/python/flatiron/torch/tools.py:237\u001b[0m, in \u001b[0;36mtrain\u001b[0;34m(compiled, callbacks, train_data, test_data, batch_size, epochs, seed, **kwargs)\u001b[0m\n\u001b[1;32m    228\u001b[0m kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mdict\u001b[39m(\n\u001b[1;32m    229\u001b[0m     model\u001b[38;5;241m=\u001b[39mmodel,\n\u001b[1;32m    230\u001b[0m     optimizer\u001b[38;5;241m=\u001b[39moptimizer,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    234\u001b[0m     \u001b[38;5;66;03m# writer=callbacks['tensorboard'],\u001b[39;00m\n\u001b[1;32m    235\u001b[0m )\n\u001b[1;32m    236\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m i \u001b[38;5;129;01min\u001b[39;00m tqdm\u001b[38;5;241m.\u001b[39mtrange(epochs):\n\u001b[0;32m--> 237\u001b[0m     \u001b[43m_execute_epoch\u001b[49m\u001b[43m(\u001b[49m\u001b[43mepoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mi\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mtrain\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdata_loader\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_ldr\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    238\u001b[0m     _execute_epoch(epoch\u001b[38;5;241m=\u001b[39mi, mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtest\u001b[39m\u001b[38;5;124m'\u001b[39m, data_loader\u001b[38;5;241m=\u001b[39mtest_ldr, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\n",
      "File \u001b[0;32m~/flatiron/python/flatiron/torch/tools.py:105\u001b[0m, in \u001b[0;36m_execute_epoch\u001b[0;34m(epoch, model, data_loader, optimizer, loss_func, device, metrics_func, writer, mode)\u001b[0m\n\u001b[1;32m    103\u001b[0m \u001b[38;5;66;03m# train model on batch\u001b[39;00m\n\u001b[1;32m    104\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m mode \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtrain\u001b[39m\u001b[38;5;124m'\u001b[39m:\n\u001b[0;32m--> 105\u001b[0m     \u001b[43moptimizer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzero_grad\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    107\u001b[0m y_pred \u001b[38;5;241m=\u001b[39m model(x)\n\u001b[1;32m    108\u001b[0m loss \u001b[38;5;241m=\u001b[39m loss_func(y_pred, y)\n",
      "File \u001b[0;32m~/pdm/envs/pdm-kVbOHlCT-dev-3.10/lib/python3.10/site-packages/torch/_compile.py:32\u001b[0m, in \u001b[0;36m_disable_dynamo.<locals>.inner\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     29\u001b[0m     disable_fn \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39m_dynamo\u001b[38;5;241m.\u001b[39mdisable(fn, recursive)\n\u001b[1;32m     30\u001b[0m     fn\u001b[38;5;241m.\u001b[39m__dynamo_disable \u001b[38;5;241m=\u001b[39m disable_fn\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mdisable_fn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/pdm/envs/pdm-kVbOHlCT-dev-3.10/lib/python3.10/site-packages/torch/_dynamo/eval_frame.py:745\u001b[0m, in \u001b[0;36mDisableContext.__call__.<locals>._fn\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    741\u001b[0m prior_skip_guard_eval_unsafe \u001b[38;5;241m=\u001b[39m set_skip_guard_eval_unsafe(\n\u001b[1;32m    742\u001b[0m     _is_skip_guard_eval_unsafe_stance()\n\u001b[1;32m    743\u001b[0m )\n\u001b[1;32m    744\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[0;32m--> 745\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    746\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    747\u001b[0m     _maybe_set_eval_frame(prior)\n",
      "\u001b[0;31mTypeError\u001b[0m: Optimizer.zero_grad() missing 1 required positional argument: 'self'"
     ]
    }
   ],
   "source": [
    "fi_torchtools.train(\n",
    "    compiled,\n",
    "    [],\n",
    "    train,\n",
    "    test,\n",
    "    batch_size=10,\n",
    "    seed=42,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9fff18a4-0934-428b-bc24-4bbef51a8ffd",
   "metadata": {},
   "outputs": [],
   "source": [
    "src = '/mnt/storage/projects/unet001/dset001/p-unet001_s-dset001_d-glom_v001'\n",
    "data = Dataset.read_directory(src).load(reshape=False).data\n",
    "\n",
    "root = '/mnt/storage/projects/unet001/dset002/p-unet001_s-dset002_d-glom_v001'\n",
    "info = pd.DataFrame()\n",
    "info['frame'] = list(range(100))\n",
    "info['asset_path'] = root\n",
    "info['filepath_relative'] = info.frame.apply(lambda x: f'data/p-unet001_s-dset002_d-glom_v001_f{x:02d}.exr')\n",
    "info['filepath'] = info.apply(lambda x: Path(x.asset_path, x.filepath_relative), axis=1)\n",
    "info['content'] = info.frame.apply(lambda x: cvd.Image.from_array(data[x]))\n",
    "\n",
    "tgt = Path(root, 'data')\n",
    "os.makedirs(tgt, exist_ok=True)\n",
    "info.apply(lambda x: x.content.write(x.filepath), axis=1)\n",
    "\n",
    "del info['frame']\n",
    "del info['content']\n",
    "del info['filepath']\n",
    "tgt = Path(root, 'p-unet001_s-dset002_d-glom_v001.csv')\n",
    "info.to_csv(tgt, index=None)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
